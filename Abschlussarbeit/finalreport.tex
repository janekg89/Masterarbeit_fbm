\documentclass[
  a4paper,BCOR10mm,twoside,
  headsepline,footsepline,% also activate headinclude and footinclude
  fleqn,openbib
]{scrbook}
\usepackage[automark]{scrpage2}
\usepackage[ngerman,english]{babel}% default language as last entry
\usepackage[utf8]{inputenc}
\usepackage{amsmath} 
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{lastpage}% to get last page use \pageref{LastPage}
\usepackage[refpage,intoc]{nomencl}% for nomenlature Abkuerzungsverzeichnis
\usepackage{listings}
\usepackage{color}
\usepackage[sort, numbers]{natbib}
\bibliographystyle{detailed}
\usepackage{hyperref}
\usepackage{subfigure} 
\usepackage[dvipsnames,svgnames,x11names,hyperref]{xcolor}
\hypersetup{colorlinks,breaklinks,
            urlcolor=gray,
            linkcolor=gray}
            
\usepackage{bm}
\usepackage{cleveref}
\usepackage{caption,setspace}
\usepackage{verbatim}
\usepackage{chemmacros}
\usepackage{wrapfig}
\usepackage{sidecap}
\usepackage{framed} 
\usepackage[font=small]{caption}
\DeclareCaptionLabelFormat{andtable}{#1~#2  \&  \tablename~\thetable}





\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\lstset{ %
  backgroundcolor=\color{white},   % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
  basicstyle=\footnotesize,        % the size of the fonts that are used for the code
  breakatwhitespace=false,         % sets if automatic breaks should only happen at whitespace
  breaklines=true,                 % sets automatic line breaking
  captionpos=b,                    % sets the caption-position to bottom
  commentstyle=\color{mygreen},    % comment style
  deletekeywords={...},            % if you want to delete keywords from the given language
  escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
  extendedchars=true,              % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
  frame=single,	                   % adds a frame around the code
  keepspaces=true,                 % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
  keywordstyle=\color{blue},       % keyword style
  language=Octave,                 % the language of the code
  otherkeywords={*,...},           % if you want to add more keywords to the set
  numbers=left,                    % where to put the line-numbers; possible values are (none, left, right)
  numbersep=5pt,                   % how far the line-numbers are from the code
  numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
  rulecolor=\color{black},         % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
  showspaces=false,                % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
  showstringspaces=false,          % underline spaces within strings only
  showtabs=false,                  % show tabs within strings adding particular underscores
  stepnumber=2,                    % the step between two line-numbers. If it's 1, each line will be numbered
  stringstyle=\color{mymauve},     % string literal style
  tabsize=2,	                   % sets default tabsize to 2 spaces
  title=\lstname                   % show the filename of files included with \lstinputlisting; also try caption instead of title
\makenomenclature
}

% define header and footer
\pagestyle{scrheadings}
\clearscrheadfoot % clear header and footer
\automark[section]{chapter}% !!! Wouldn't do that at oneside documents!!!
%\ihead[]{\leftmark}% header left part
\ohead[]{\rightmark}% header right part
%\ifoot{Name}% footer left part
%\cfoot{Thema}% footer middle part
\makeatletter
% use different foot at front and main matter
\g@addto@macro{\mainmatter}{%
  \ofoot[{\usekomafont{pagenumber} \pagemark\ }]
    {\usekomafont{pagenumber} \pagemark\ }% footer right part
}
\g@addto@macro{\frontmatter}{%
  \ofoot[\pagemark]{\pagemark}%
}
\makeatother

\textheight=610pt

\begin{document}
\frontmatter% title pages are not numbered but counted!
\begin{titlepage}
  \raggedright% Use a different title style
  \null% page started
  \thispagestyle{empty}
  \selectlanguage{english}
  \vspace{4\baselineskip}
  \begin{tabular}{|ll@{}}
    & \\[\baselineskip]
    & \large Master Thesis\\
    & \large Jan Grzegorzewski \\[\baselineskip]
    & \huge\textbf{Reaction-Diffusion Dynamics} \\
    & \huge\textbf{With Fractional Brownian Motion}\\[\baselineskip]
    & \large Winter term: 2016\\[2\baselineskip]
  \end{tabular}
\end{titlepage}

\tableofcontents
%\listoffigures
%\listoftables

\mainmatter
\selectlanguage{ngerman}
\selectlanguage{english}
\printnomenclature
\clearpage

\newtheorem{mydef}{Definition}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\chapter*{Motivation}
Anomalous diffusion can be observed in many different areas of nature, in particular, related to heterogeneous media like porous rocks, gels and crowded biological media with its prominent phenomena macromolecular crowding, confinement and macromolecular adsorption \cite{Minton2006}. These environments exhibit remarkable characteristics like anomalous diffusion with its most popular power-law behaviour of the mean-square-displacement ($\delta r^2(t)\propto t^{\alpha}$) \cite{Hofling2013}, which violates the Einstein formula $\delta r^2(t)=2 d D t$ and thereby the central limit theorem. Anomalous diffusion is described by various theoretical models like the time random walks (CTRW) with an unconventional waiting time-distribution, the Lorentz models with excluded volume and a highly ramified remaining space  or fractional Brownian motion (fBm). The latter is modelling a stochastic process with long-range correlations of the increments. FBm was first introduced as a family of Gaussian random functions by Mandelbrot and Van Ness in 1968 and motivated by examples in economics \cite{Mandelbrot1968}. In contrast to different models of anomalous diffusion, the fBm approach is plainly phenomenologically defined by a power-law increase of the MSD and thus perfectly qualifies as a starting point to study effects arising from a power-law increase of the MSD. \par This thesis focuses on the impact of fBm on enzymatic reaction kinetics in three-dimension space. Enzymes are large biological molecules, mostly proteins. Metabolic processes in cells rely vitally on enzymes. They help to break down large nutrient molecules like carbohydrates, fats and proteins during in the process of digestion. Other enzymes contrariwise help to form large and complex molecules from smaller once. Enzymes are involved in storage and release of energy, processes of respiration, vision, muscle contraction and transmission of nerve impulses. In fact, biochemical reactions are controlled mainly by enzymes. In general, they act as catalysts by lowering the activation energy. As stated by the Arrhenius law the activation energy is then increasing the reaction rates. The speed of reactions is typically increased by a factor of $10^6-10^{14}$. Pioneer work by Leonor Michaelis and Maud Menten \cite{michaelis1913kinetik} simplified enzymatic reaction kinetics and formulated a model based on the law of mass action. As one of the best known and important models of enzyme kinetics, it is of great interest to study effects from anomalous diffusion on Michaelis-Menten like reactions. For this purpose a particle-based simulation with an fBm integrator of a Michaelis-Menten like reactions was set up. Spatial and temporal effects induced by fBm were studied. 
\par The thesis is organised into four chapters: The first chapter sets up theoretical foundations for fBm. Subsequently, fBm-generating algorithms are studied. Chapter 2 deals with models describing reactions in general but focuses on particle-based reaction-diffusion. A particle-based reaction-diffusion software RevReaDDy, which served as a starting point for the implementation is introduced.  Chapter 3 focuses more specifically on enzyme reactions. Followed by an enzymatic simulation model set up with RevReaDDy. Finally, results of the simulation are discussed and related to existing literature. Chapter 4 summarises the content of the thesis. 
\chapter{Fractional Brownian Motion}
The Wiener process is a continuous-time stochastic process, which models white noise. It is applied to finance, biology, physics and much more if no or only weak correlations of the underlying processes are present. Brownian motion is the random motion of particles suspended in a fluid, which is modelled by a Wiener process. Velocities of particles, however, are always correlated at least for very short lag times in the physical world. It is often referred to as the super-diffusive regime. A $1 \mu $  silica bead in water for examples forgets its initial velocities in about $0.3ns$ within the corresponding displacement of about $1pm$ \cite{Huang2011}. For longer times Brownian motion can be assumed.\par
Fractional Brownian Motion (fBm) is a more general family of stochastic Gaussian processes than standard Brownian motion with long-range correlations as its defining property. The main objective of this chapter is to explore the theoretical foundation for fBm starting with Brownian motion in the following section. Further fBm-generating algorithms are introduced and analysed in terms of accuracy and performance.    
\section{Brownian Motion}
Standard Brownian Motion (Bm) is a very important and well studied stochastic process. It describes the erratic motion of mesoscopic particles, which first were documented by Jan Ingenhousz in 1785, in particular for coal dust on the surface of alcohol \cite{Hofling2013}. Later on, in 1827 Robert Brown observed the erratic motion of pollen grains. Brownian motion has a Gaussian propagator, which has its origin in the Central Limit Theorem (CLT) for a sum of independent and identically distributed random variables (i.i.d.). Let's assume a set of $N$ independent variables $\{X_j\}$ with a finite variance $ \sigma_j^2=\langle X_{j}^2\rangle $ and the mean $\langle X_{j}\rangle = 0$. The definition of another random variable $Y$ is given by:
 \begin{align}
  Y = \frac{1}{\sqrt{N}} \sum_{j=1}^N X_j \label{eq:CLT}
 \end{align}
This scenario in which a random variable is defined by the sum of another can be observed generically in nature. $X_j$ are called increments of $Y$. The seemingly innocent assumption of independent increments result in a Gaussian distribution of $\rho(y)$ in the limit of large N with $\rho(y)dy=\mathrm{P}(y<Y<y+dy)$:
\begin{align}
 \rho(y) =\frac{1}{\sqrt{2 \pi} \sigma } \exp \left(-\frac{y^2}{2 \sigma^2}\right)
\end{align}
A derivation of this very interesting result can be found in the appendix \ref{append:CLT}. Microscopic processes with i.i.d. velocities, thus have a Gaussian distribution for the overall change in position. Indeed, even the increments of Brownian motion are distributed Gaussian as a result of i.i.d. velocities at shorter time scales. A random walk in the limit of very small time steps, therefore, converges to Brownian motion. \par With  Bayes' theorem and an initial delta-distribution one can show that the transition probability $T_{t}(y|0) = \rho_{t}(y)$ is equivalent to the particle density distribution. One can find the calculation in the appendix \ref{baystheorem}. The above-mentioned elaborations motivate the reason for a process with a Gaussian transition probability. A process with Gaussian distributed transition probability and independent increments is called Wiener process (Standard Brownian motion).\par
Brownian motion described by the Wiener process is a stochastic process $ \{ W_t \}: \Omega \rightarrow \mathbb{R}^d$ with $ W_t(\omega)$ being the position of a particle with $\omega \in \Omega$ at time $t \in T$ in the observation time $T =[0, \infty)$. It has a fixed $x \in \mathbb{R}^d$ as its origin. The transition probabilities are \cite{LectureFelix}: 
\begin{align}
T_{t}(y|x) & := (2 \pi t)^{-d/2} exp \left(- \frac{||x-y||^2}{2 t}\right) \qquad  \text{ for } \quad y \in \mathbb{R}^d, t>0 \\ \nonumber
T_{0}(y|x) & = \delta(x-y) 
\end{align}
The Wiener process is a Gaussian process with mean $\langle W_t \rangle_y=x$ and particle position $W_o=x$ at $t=0$. Its variance is $\langle W^2_t \rangle_y= t$. It has stationary, independent, Gaussian increments. Following from the definition, Brownian motion has a property called Brownian scaling:
\begin{align}
\label{Brownianscaling}
\{\hat{W}_t := \frac{1}{c} W_{c^2 t} \}_{t\geq0} 
\end{align}
A Wiener process has self-similar and fractal paths as a result from Brownian scaling.\par\bigskip
However, it is a purely mathematical model with a missing connection to the strength of diffusion of a particle. The process, in fact, is a normalised diffusion process with the diffusion constant $D=\frac{1}{2}$. A mathematical description of diffusion was first realised by Fick in 1855 \cite{Fick1855}. He applied partial differential equations for heat transfer, first solved by Fourier in 1822 \cite{Fourier1822}. Fick's  second law of diffusion describes how diffusion causes the concentration ($c(\bm{r},t)$) to change over time:
\begin{align}
 \frac{\partial}{\partial t} c(\bm{r},t) = - \nabla J (\bm{r},t) = D  \Delta c(\bm{r},t) \qquad \text{ with } \qquad \Delta= \nabla^2  \label{eq:ficks}
\end{align}
With Fick's first law $J(\bm{r},t)=- \nabla c(\bm{r},t)$ and $D$ defining the flux of particles and the diffusion coefficient, respectively. The notation of bold letters is chosen to describe vectors (e.g. $\bm{r}$). Fick's first law is a result from the linear response theory. Fick's second law can be derived from mass conservation and Fick's first law. The most general form of mass conversation with a production term $\sigma$ is described by the continuity equation:
\begin{align} \label{continuity}
\frac{\partial}{\partial t} c(\bm{r},t)=- \nabla J(\bm{r},t)+ \sigma 
\end{align}
Albert Einstein in 1905 proposed a similar equation to Fick's second law of diffusion to solve one-dimensional Brownian motion \cite{Einstein1905}. This was the first derivation and application of probabilistic stochastic theory. Derived from the kinetic gas theory and a statistical description of collisions, in 1906 Marian von Smoluchowski could give similar results to Einstein \cite{vonSmoluchowski1906}. The concentration $c(\bm{r},t)$ is proportional to the transition probability $\mathrm{P}(\bm{r},t) \propto c(\bm{r},t)$ and  $\int d\bm{r}\mathrm{P}(\bm{r},t)=1$. The transition probability of the Wiener process builds the foundation for a more physical description of particle motion by a propagator:
\begin{align}
 \mathrm{P}(r,t)=  \left(4 \pi D t\right)^{-d/2} \exp \left(- \frac{r^2}{4 D t} \right) \label{propagator}
\end{align}
The propagator $\mathrm{P}(r,t)$ can be interpreted as the probability to move the distance $r$ during the time $t$. $d$ is the dimension of the space of $\bm{r}$. One can show that this propagator is, in fact, solving the diffusion equation \cref{eq:ficks} with the meaningful initial condition of vanishing concentration at boundaries: 
\begin{align}
c(\pm \infty,t)=0
\end{align}
The calculation can be found in the appendix \ref{einsteinrealtionappendix}. The most important property of Brownian motion in the context of this thesis  is the mean square displacement ($\delta r^2(t)$), which grows linearly with the number of steps: 
\begin{align}
\delta r^2(t)=<[\bm{R}(t)-\bm{R}(0)]^2>= 2dDt                                                                                                                                                                                                                                                                                                                                \end{align}
Here, $\bm{R}(t)$ is the position of the particle at time $t$.
Brownian scaling was mentioned as a property of a Wiener process. It obviously also applies as a property to the propagator of Brownian motion. A scale-free form of the Gaussian propagator exists as a more intuitive consequence of Brownian scaling: 
\begin{align}
\mathrm{P}(r,t)&= r^{-d} \mathcal{P}_{gauss}(\hat{r}) \\ \text{with} \quad \hat{r} &= \frac{r}{\sqrt{2Dt}} \quad \text{and} \quad \mathcal{P}_{gauss}(\hat{r})= (2 \pi)^{-d/2}  \hat{r}^d \exp \left(- \frac{\hat{r}^2}{2} \right) \label{scalefreeform} 
\end{align}
The scale free form of Bm can later on be compared to the scale free form of fractional Brownian motion, which will be introduced next. This property results in a neat possibility of analysis of Bm and fBm-generating algorithms later on.


% Now some stuff from \cite{Timmer1995}
% and its autocorrelation
% \begin{align}
% VACF&=\langle (W_{t_i}-W_{t_{i-1}})(W_{t_j}-W_{t_{j-1}}) \rangle_x \\
% &=\lim\limits_{n \rightarrow \infty}\frac{1}{N}\sum_{t=1}^{N-(t_i-t_j)}(W_{t_i}-W_{t_{i-1}})(W_{t_j}-W_{t_{j-1}}) =
% \end{align}


\section{Fractional Brownian Motion}\label{sectionfrac}
\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{./data/trajectories_differentalpha1234.png}
\caption{A three-dimensional fBm trajectories for the anomalous coefficient $0.01\leq\alpha\leq 1$ generated by the Lowen algorithm are shown. The general diffusion constant, the time step and trajectory length were chosen as follows:  $K_{\alpha}=1$, $\Delta t=1$, $M=1000$.}
\label{alphachangetrajectory}
\end{figure}
In the previous section, the MSD has been shown to be linear with time as a result of the central limit theorem. In normal liquids, this behaviour can be seen already at time scales higher than picoseconds \cite{Hofling2013}. Nevertheless, many experiments show that the MSD has a power law behaviour ( $\delta r ^2 (t) \propto t^{\alpha}$ for  $0 < \alpha < 1$ ) over certain time windows from  microseconds to even seconds. Thus, the central limit theorem does not hold, at least in theses time scales. It can be shown that persistent correlations of the increments are present. In soft matter, like polymers, a sub-diffusive behaviour is typically present in a time window but finally, the linear MSD takes over. Fractional Brownian motion idealises this situation by imposing that the central limit theorem is violated even for all time scales. The basic feature of fBm is that the "span of interdependence" between their increments can be said to be infinite \cite{Mandelbrot1968}. \par
Just like the Wiener process, continuous-time Fractional Brownian motion (ctfBm) is a continuous-time Gaussian process $\{B^{\alpha}_t\}: \Omega \rightarrow \mathbb{R}^d$ at time $t \in T$ in the observation time $T =[0, \infty)$. It is fully specified by its mean $\langle B_t \rangle=0$ and its covariance function:
\begin{align}
\mathrm{Cov}[B^{\alpha}_t,B^{\alpha}_s]=\frac{\sigma^2}{2}[t^{\alpha}-2(s-t)^{\alpha}+s^{\alpha}] \qquad \text{for} \qquad t<s \label{correlationfunctionfbm}
\end{align}
With the mean and the covariance defined, the mean square displacement for fBm can be derived as: 
\begin{align}
\label{MSDfbm}
 \langle (B^{\alpha}_{t}-B^{\alpha}_{s})^2 \rangle = (s-t)^\alpha \sigma^2
\end{align}
Fractional Brownian motion exhibits a power law behaviour of the mean square displacement and therefore indeed motivates to act as a model for anomalous diffusion.\par Fractional Brownian motion can be alternatively expressed in terms of its incremental sequence. The incremental sequence is a related stochastic process called continuous-time fractional Gaussian noise (ctfGn). CtfGn is a continuous-time Gaussian process $\{X^{\alpha}_t\}: \Omega \rightarrow \mathbb{R}^d$ at time $t \in T$ in the observation time $T =[0, \infty)$. The mean is zero  $\langle X^{\alpha}_t \rangle=0$   and variance $\mathrm{Var}[X^{\alpha}_t]= \langle (X^{\alpha}_t)^2 \rangle=\sigma^2$:
\begin{align}
  B^{\alpha}_t=\int^t_s X^{\alpha}_{t'} d t' +  B^{\alpha}_s \qquad \text{for} \qquad t<s
\end{align}
The covariance function for ctfGn can be derived from the covariance function of fractional Brownian motion:
\begin{align}
\mathrm{Cov}[X^{\alpha}_t,X^{\alpha}_s]&= \frac{d^2}{dt ds} \mathrm{Cov}[B^{\alpha}_t B^{\alpha}_s]=\sigma^2 \frac{d^2 |t-s|^{\alpha}}{dtds} \label{eq:covfgn} \\
 &=\alpha (\alpha-1) \sigma^2 |t-s|^{\alpha-2}+\alpha \sigma^2 |t-s|^{\alpha-1} \delta(t-s) \label{eq:covfgn1}
\end{align}
The first term of this covariance function is describing the correlation of the increments. For Wiener white noise ($\alpha=1$) the first term disappears and the second reduces to:
\begin{align}
 \mathrm{Cov}[X_t,X_s]= \sigma^2 \delta(t-s)
\end{align}
The description of fractional Brownian motion in terms of fractional Gaussian noise is often convenient because of fGn's stationarity. It is possible to apply the Wiener-Khinchin theorem on a stationary random process. Thus, a spectral decomposition exists.The Wiener-Khinchin theorem states that, the power spectral density can be written as the Fourier transform of the auto-covariance function:
\begin{align}
 S(\omega)= \int^{\infty}_{-\infty} \mathrm{Cov}[X_t,X_0] \exp[-2 \pi i \omega t] dt
\end{align}
The power spectral density for fGn for $\omega \longrightarrow 0$ can be written as \cite{Hofling2013}:
\begin{align}
 S(\omega)_{fGn}= \sigma^2 \Gamma(1+\alpha) (-i \omega)^{1-\alpha} \label{powerspec}
\end{align}
For the Wiener white noise ($\alpha=1$), the result simplifies to a constant:
\begin{align}
 S(\omega)_{Gn} = \sigma^2 
\end{align}
For fBm-generating algorithms, the discrete time version of fractional Brownian motion (fBm) and Gaussian noise (fGn) are interesting as well. The relation between them can be written as:
\begin{align}
B^{\alpha}_{t}= \sum_{i=0}^kX^{\alpha}_{t_i} \qquad \text{with} \qquad t_i= t_0+i \Delta t
\end{align}
The covariance function of discrete time fractional Gaussian noise is:
\begin{align}
 \mathrm{Cov}[X^{\alpha}_n,X^{\alpha}_m]&=\langle (B^{\alpha}_{n+1}-B^{\alpha}_n) (B^{\alpha}_{m+1}-B^{\alpha}_m)\rangle \nonumber \\ &=\frac{\Delta t^{\alpha} \sigma^2}{2}[(n-m-1)^{\alpha}-2(n-m)^{\alpha}+(n-m+1)^{\alpha}]\\ &  \text{for}  \quad n\geq m \nonumber
\end{align}
Due to stationarity one can write the auto-covariance function as:
\begin{align}
 \mathrm{Cov}[X^{\alpha}_0,X^{\alpha}_n]=\frac{\Delta t^{\alpha}\sigma^2}{2}[(n-1)^{\alpha}-2n^{\alpha}+(n+1)^{\alpha}] \label{autocovfgn}
\end{align}
A more detailed study of fBm and fGm can be found in \cite{qian2003fractional}.\par \bigskip Similar to the line of argument for Brownian motion, also fBm needs a connection to the strength of diffusion. This connection is introduced by the variance of fGn as: 
\begin{align}
\label{diffusionvariance}
\sigma^2=2dK_{\alpha} 
\end{align}
The mean square displacement for fBm follows from \cref{MSDfbm} as:
\begin{align}
\delta r^{2}(t)=2dK_{\alpha} t^{\alpha}
\end{align}
Here,  $K_{\alpha}>0$  is the generalised diffusion coefficient of the physical dimension $ \mathrm{cm^2/sec^{\alpha}} $. The more physical description in terms of a propagator is the correlation function of the single particle density $P(\bm{r}-\bm{r}',t-t')= V\langle\rho(\bm{r},t) \rho(\bm{r}',t')\rangle$. Here, the single particle density $\rho(\bm{r},t)=\langle \delta(\bm{r}-\bm{R}(t))\rangle$ describes the density of a particle, which is localised at position $\bm{R}(t)$. $V$ is the volume. Just like Brownian motion, fractional Brownian motions increments $\Delta \bm{R}$ are Gaussian distributed with zero mean. The single particle density results in:
\begin{align}
 P(\bm{r},t)=[4 \pi K_{\alpha} t^{\alpha}]^{-d/2} \exp \left[ \frac{-|\bm{r}|^2}{ 4 K_{\alpha} t^{\alpha} }\right]
\end{align}
The propagator of fBm can be transformed into a scale-free form. A scale-free form will be relevant in the analysis of the algorithm. It is related to the scale-free form of standard Brownian motion \cref{scalefreeform}:
\begin{align}
P(\bm{r},t)&= \bm{r}^{-d} \mathcal{P}_{gauss}(\hat{\bm{r}}) \\ \text{with} \qquad \hat{\bm{r}} &= \frac{\bm{r}}{\sqrt{2 K_{\alpha} t^{\alpha}}}  \quad \text{and} \qquad \mathcal{P}_{gauss}(\bm{\hat{r}})= (2 \pi)^{-d/2}  \bm{\hat{r}}^d \exp \left(- \frac{|\bm{\hat{r}}|^2}{2} \right)\label{scalefreeformfrac}
\end{align}
Velocities ($\bm{\xi}(t)$) in the physical world can be described by fractional Brownian noise. The velocity auto-correlation function (VACF) ($Z(t)$) can be expressed from the auto-covariance function of fGn as defined in \cref{eq:covfgn}:
\begin{align}
Z(|t-t'|)&= \frac{1}{d}\langle \bm{\xi}(t) \bullet \bm{\xi}(t') \rangle = \frac{1}{2d} \frac{d^2}{dt^2} \delta r^2 (t-t')  
\end{align}
The frequency representation of the velocity auto-correlation function of fractional Brownian motion is defined analogously to \cref{powerspec} as:
\begin{align}
  \tilde{Z}(\omega) =  K_{\alpha} \Gamma(1+\alpha)(i \omega)^{1-\alpha}
\end{align}
\begin{comment}
\item The van hove correlation function can be transformed via the spatial Fourier transform into its wave-number representation, which is called the self-intermediate scattering function. Again for isotropic systems one can write $|\bm{k}|=k$.
\begin{align}
 F_{s}(k,t)&=\langle\rho(k,t) \rho(k',t')\rangle=\int d^{d}r e^{-i k r} P(r,t) \\
 &=\langle e^{-i k \Delta R(t)} \rangle
\end{align}
\item 
\end{comment}
For the analysis of fBm-generating algorithms an indicator, if the created increments indeed are Gaussian, will be of interesting. One can show that for Gaussian propagators with zero-mean, all but the second cumulants vanish. For non-Gaussian transport also further cumulants are non-zero. The cumulants can be obtained by expanding the characteristic function of $\Delta R(t)$ for small wave numbers $k \rightarrow 0$. Its logarithm returns the cumulants. From the cumulants, the so-called non-Gaussian parameter can be defined \cite{Hofling2013}:
\begin{align}
 \mathrm{NGP}(t)=\frac{d \delta r^{4}(t)}{(d+2) [\delta r^{2}(t)]}-1 \label{nongaussian2}
\end{align}
The non-Gaussian parameter reveals non-Gaussian transport if $\mathrm{NGP}(t)>0$. This, in turn, does not lead to sure Gaussian transport for $\mathrm{NGP}(t)=0$. Cumulants of higher order still can be non-zero. 
\begin{comment}
An other important quantity is the dynamical structure factor, which is the time-frequency Fourier transform of the intermediate scattering function:
\begin{align}
 F_{s}(k,z)&=\langle\rho(k,z) \rho(k',z')\rangle=\int_{0}^{\infty} d t e^{-i t z} P(k,t) \text{ for } k \rightarrow 0 , \operatorname{Im}(z) > 0 \label{dynamicstructurfactor}\\
 &= \frac{1}{-iz}-\frac{k^2}{2d}\int_{0}^{\infty} d t e^{izt} \delta r^2 (t) + \mathcal{O}(k^2)
\end{align}
For the velocities as our random variables $\partial_t \bm{R}(t)=\bm{\xi}(t)$ also the Velocity auto correlation function is of interest. Velocities correspond to continuous-time fractional Gaussian noise in the mathematical description. 

\begin{itemize} 
\item Velocities can be used to calculated the Velocity Autocorrelation Function (VACF):
\begin{align}
Z(|t-t'|)&= \frac{1}{d}\langle \bm{\xi}(t) \bm{\xi}(t') \rangle = \frac{1}{2d} \frac{d^2}{dt^2} \delta r^2 (t-t')  
\end{align}
The VACF in the frequency domain for fBm is: 
\begin{align}
  \tilde{Z}(z) \stackrel{\operatorname{Im}(z)> 0} {=}  K_{\alpha} \Gamma(1+\alpha)(i z)^{1-\alpha}
\end{align}
The calculation can be found in the appendix \ref{VACF}
\end{itemize}
\end{comment}

\section{Algorithm}
Effects of anomalous diffusion increase their relevance for long times. Thus, a fractional Brownian motion generating algorithm for preferably long trajectories is going to be searched for. Exactness and performance of the algorithm matter. In literature, several algorithms are described. Promising exact methods are: Cholesky \cite{Dieker2004}, Hosking \cite{WRCR:WRCR3676}, Davis-Harte \cite{Dieker2004} and  Lowen \cite{Lowen1999} method. Cholesky  method claims to perform $\mathcal{O}(M^3)$ with the length of trajectory $M$ and $\mathcal{O}(M^2)$ for every next trajectory. Davis-Harte and Lowen method claim to be exact and fast $\mathcal{O}(M log(M))$ \cite{DAVIES1987}\cite{Lowen1999}. There are further algorithms with even faster performance (e.g. the $RMD_{3,3}$- method \cite{Dieker2004} with $\mathcal{O}(M)$) . However, they are approximations. In order to choose an algorithm, four algorithms were analysed in terms of accuracy and speed. 1.Cholesky  2. Davis-Harte 3.Lowen and 4. an own naive algorithm. All the methods are based on one or the other correlation functions described in the previous section.  
\subsubsection{Cholesky Method}
\begin{table}
\begin{framed}
\begin{enumerate}
 \item Calculate the covariance matrix of fGn:
 \begin{align}
  \Gamma=(\mathrm{Cov[x_i,x_j]}) \quad , \\  \mathrm{Cov[x_i,x_j]}=\Delta t^\alpha \sigma^2(i^{\alpha}+j^{\alpha}-|i-j|^\alpha)/2
 \end{align}
\item Calculate the eigenvalues $\lambda$ and eigenvectors $\bm{v}$ of $\Gamma$ 
\item Compute $\Sigma$ the square root of $\Gamma$ by the eigenvalues.
\item Draw for every entrance of the vector $\bm{\eta}$  a standard Gaussian distributed random number. Length of the vector is defined by the length $M$ of the trajectory:
\begin{align}
 \eta_k= \mathcal{N}(0,1) \quad \text{,}  \qquad k=0,1,2,...,M 
\end{align}
\item Calculate the fGn by $B^{\alpha}_k =\Sigma \bm{\eta_k}$.
\end{enumerate}
\end{framed}
\caption{The table shows Choleskys fBm-generating method.}
\label{Choleskimethod}
\end{table}
The Cholesky method \cite{Dieker2004} is based on the auto-covariance function of fGn as described by \cref{correlationfunctionfbm}. The algorithm is shown in \cref{Choleskimethod}. This approach is simple but as claimed by \citet{Dieker2004} unfortunately not efficient with an algorithmic scaling of $\mathcal{O}(M^3)$ with the trajectory length ($M$). Performance and accuracy of all algorithms are discussed in detail in the last two sections of the chapter.
\subsubsection{A Naive Algorithms}
\begin{table}
\begin{framed}
\begin{enumerate}
 \item Generate $4M$ independent normally distributed random increments: 
\begin{align}
 \eta_k \sim \mathcal{N}(0,\sqrt{\Delta t})\quad, \qquad k=0,1,2,...,4M 
\end{align}
\item Fourier transform the increments via FFT into the frequency domain:
\begin{align}
 \tilde{\eta_l}=\sum_{k=0}^{4M-1} \eta_k \exp\left[\frac{- i 2 \pi  l k }{4M}\right] \Delta t \quad , \qquad  l=0,1,2,...,4M  \label{eq:fouriertrans}
\end{align}
\begin{comment}
By comparison with the \cref{eq:fourier} one can see that:
\begin{align}
 z \rightarrow  l \Delta z \text{ , } \Delta z =   \frac{2 \pi }{M \Delta t} \teFxt{ , } t \rightarrow j \Delta t \text{ and } \int dt \rightarrow \sum \Delta t \label{eq:diskret-freq} 
\end{align}
 \end{comment}
\item Generate fractional increments in the frequency domain with the VACF: 
 \begin{align}
   \tilde{\xi}_{l}&= \tilde{\eta}_l\sqrt{2 Re( \tilde{Z}_l)} \label{eq:problem} 
  \end{align}
 Here,  $ \tilde{Z}_l$ is the discrete VACF in the frequency domain:
  \begin{align}
   \tilde{Z}_l = K_{\alpha} \Gamma(1+\alpha)(i 2 \pi l \Delta \omega)^{1-\alpha} =  K_{\alpha} \Gamma(1+\alpha)\left( \frac{i l 2 \pi}{4 M \Delta t}\right)^{1-\alpha} 
 \end{align}
 
 \item Replace the zero-increment in the frequency domain with:
\begin{align}
 \tilde{\xi}_{l=o} = \mathcal{N}(0,\sqrt{2 K_{\alpha} (4 M \Delta t)^\alpha})
\end{align}
 \item Reverse Fourier transform the increments into the time domain:
 \begin{align}
 \xi_{k}= \frac{1}{4M} \sum_{l=0}^{4M-1}  \tilde{\xi}_l \exp\left[\frac{2 \pi i l k }{4M}\right] \Delta \omega
 \end{align}
 \item Build the cumulative sum only for the first quarter of the total number of generated increments: 
 \begin{align}
   B^{\alpha}_n= \sum^{n-1}_{k=0} \xi_k ,\qquad n=(0,1,..,M)
  \end{align}
\end{enumerate}
\end{framed}
\caption{The table shows a naive fBm-generating algorithm.}
\label{naivealgorithm}
 \end{table}
\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{./data/nocorrectionmsd1.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{An ensemble-average mean square displacement of two versions of the naive algorithm. The green curve is the MSD of the algorithm with the correction introduced in step 4 and the blue curve without.}
  \label{fig:41}
\end{figure}
In this section, a naive algorithm based on the VACF in the frequency domain is introduced. This was the first attempt of a fast fBm algorithm, without any insight from the existing literature. The idea is to compute the increments in the frequency domain and eventually transform them back to the time domain. The algorithm is described in \cref{naivealgorithm}. In the first step of the algorithm, four times the number of increments in comparison to the trajectory length are generated. It counteracts a problem arising from the boundary problem of the FFT. The problem is visualised in \cref{fig:41}. The figure shows an ensemble-averaged mean square displacement for $\alpha=0.5$ for two versions of the algorithm. One curve in the figure is for the algorithm with a modification introduced in step 4. The other is for now of interest. It can be seen that on average all the particles travel back to their initial position. It is not shown in the plot, however, this is even true for every trajectory. The FFT has a downside compared to the continuous Fourier transform, which causes this effect. The VACF is zero at zero-frequency $ \tilde{Z}_{l=0}=0$.  From \cref{eq:problem} also the first increment in the frequency domain is zero $ \tilde{\xi}_{l=0}=0$. Due to \cref{eq:fouriertrans} also the following relation holds:
 \begin{align}
   \tilde{\xi}_{l=0} = \sum_{k=0}^{M-1} \xi_k e^{0} \Delta t = \Delta  R_{M} \label{correction}
 \end{align}
$\Delta R $ is the distance between the starting point and the position of the particle. Therefore, the particle would travel after $M$ steps back to its initial position. The naive idea is to generate a trajectory four times longer than the desired length and only take the first forth into consideration. This can be thought of as a finite-time correction. The cut is displayed as a vertical red dashed line. The plot suggests not a perfect but at least a better agreement of the generated data to the theoretical mean square displacement for short times. Hereafter the normally distributed random numbers are transformed into the frequency domain. Wiener-Khinchin's theorem suggests to multiply the random numbers with the square root of two times VACF. Besides taking only one-quarter of the trajectory a modification to the algorithm was introduced in step 4. Its impact in the MSD is shown in \cref{fig:41} as the green line. Instead of accepting  \cref{correction}, the zero-frequency increment is calculated as follows:
\begin{align}
 \tilde{\xi}_{l=0} = \mathcal{N}(0,\sqrt{2 K_{\alpha} (M \Delta t)^\alpha})
\end{align}
This equation would be correct if we assumed fractional Brownian motion to be a Markovian process. This is certainly is not the cause. This approximation seems to improve the accuracy only slightly.
Finally in step 4 the increments are back transformed into the time domain and in step 5 the cumulative sum of fGn is calculated, which yields fBm. The described algorithm can be performed independently for every Cartesian component for a three-dimensional fractional Brownian motion. Different Cartesian components are independent. Without any extensive analysis of the naive algorithm one can already conclude draw backs in terms of convergence close to the overall simulation time. 
\begin{comment}
in step 4: The discrete Fourier transform has a downside compared to the continuous Fourier transform, as already noted in the beginning of this section. The VACF is zero at zero-frequency $ \tilde{Z}_{l=0}(z=0)=0$.  From \cref{eq:problem} also the first increment in the frequency domain is zero $ \tilde{\xi}_{l=o}(z=0)= 0$. Due to \cref{eq:fouriertrans} also the following relation holds:
 \begin{align}
   \tilde{\xi}_{l=o}(z) = \sum_{k=0}^{M-1} \xi_k e^{0} \Delta t = \Delta  R_{M} \label{correction}
 \end{align}
$\Delta R $ is the distance between the starting point and the position of the particle. Therefore, the particle would travel after $M$ steps back to its initial position. The effect on the ensemble averaged mean square displacement can be seen in \cref{fig:6}. 

will be used to modify standard Brownian motion velocities, which are easily computable, to generate increments. The starting point are the velocities $\partial_t \bm{R}(t)=\bm{\xi}(t)$. The increments can be decomposed in its Fourier modes for real frequencies $z=\omega$:
\begin{align}
 \tilde{\bm{\xi}}_{T}(\omega)=\int_{-\frac{T}{2}}^{\frac{T}{2}} dt e^{i \omega t} \bm{\xi}(t) \label{eq:fourier}
\end{align}
For a finite observation time T the Wiener-Khinchin theorem applies :
\begin{align}
 \lim_{T\to\infty}\frac{1}{T}\langle \lvert  \tilde{\bm{\xi}}_{T}(\omega) \rvert^2  \rangle = 2  \operatorname{Re} \left(\tilde{Z}(\omega)\right)
\end{align}
For white noise one gets: 
\begin{align}
 \lim_{T\to\infty}\frac{1}{T}\langle \lvert  \tilde{\bm{\eta}}_{T}(\omega) \rvert^2 \rangle = const.
\end{align}
Fractional correlations can be incorporated via its VACF:
\begin{align}
\tilde{\bm{\xi}}(\omega) = \sqrt{2 \operatorname{Re} \left(\tilde{Z(\omega)}\right)}  \tilde{\bm{\eta}}(\omega) \label{eq:fracvacf}
\end{align}
 With $\tilde{\bm{\xi}}(\omega)$ being fractional Brownian velocities in the frequency domain. Its Fourier-back-transform results in fractional Brownian velocities in the time domain.
\begin{align}
\bm{\xi}(t)=\int d \omega e^{i \omega t} \tilde{\bm{\xi}}(\omega) \label{eq:fourier2}
\end{align}
In the following an algorithm, which generates fractional Brownian noise will be introduced. The algorithm is based on the Davis-Harte algorithm \cite{Craigmile2003}. The idea is to use the calculated VACF and thereby modify conventionally generated Gaussian random variables. All the increments should be generated beforehand. With this concept it is difficult to include forces. For computational reasons the previous elaborations on how to generate fractional Brownian increments have to be transformed into a discrete form, thereby the solution is no longer exact, which will be shown in the analysis part of the algorithm.  
\begin{align}
\bm{\eta} (t) \longrightarrow \bm{\eta}_j(t)  \text{  with  } j=0,1,2,...,n  \text{  ,  } n= \text{amount of steps}
\end{align}
For a n-steps long trajectory one can write:
\begin{align}
 \Delta \bm{R}_n(t) =  \sum_{j=0}^n \bm{\eta}_j  \Delta t \label{eq:diskretdeltar}
\end{align}
 The following algorithm is explained for one dimension and can be easily extended for more dimensions. The MSD can be written as:
\begin{align}
< \Delta R_{j}(t)>=2K_{\alpha} (\Delta t j)^{\alpha}
\end{align}
The algorithm goes as follows:
\begin{enumerate}
 \item $M$ independent normally distributed random increments are generated: 
\begin{align}
 \eta_k(t)= \mathcal{N}(0,\sqrt{\Delta t}) \text{  with  } k=0,1,2,...,M 
\end{align}

$M>n$  more increments are generated to counteract the boundary problem in the discrete Fourier transform, which is shown in \cref{fig:6} and \cref{fig:5}

\item Via discrete Fourier transform these increments are transformed into the frequency domain:
\begin{align}
 \tilde{\eta_l}(z)=\sum_{k=0}^{M-1} \eta_k e^{\frac{- i 2 \pi  l k }{M}} \Delta t   \text{  with  }  l=0,1,2,...,M  \label{eq:fouriertrans}\\ 
\end{align}
By comparison with the \cref{eq:fourier} one can see that:
\begin{align}
 z \rightarrow  l \Delta z \text{ , } \Delta z =   \frac{2 \pi }{M \Delta t} \text{ , } t \rightarrow j \Delta t \text{ and } \int dt \rightarrow \sum \Delta t \label{eq:diskret-freq} 
\end{align}
 
\item Comparable to \cref{eq:fracvacf} correlations are incorporated: 
 \begin{align}
   \tilde{\xi}_{l}(z)&= \tilde{\eta}_l(z) \sqrt{2 Re( \tilde{Z}_l(z))} \label{eq:problem} 
  \end{align}
 with $\tilde{Z}(z)\rightarrow \tilde{Z}_l(z)$ as introduced in \cref{eq:diskret-freq}:
  \begin{align}
   \tilde{Z}_l(z) = K_{\alpha} \Gamma(1+\alpha)(i 2 \pi l \Delta z)^{1-\alpha} =  K_{\alpha} \Gamma(1+\alpha)(i l \frac{ 2 \pi}{M \Delta t})^{1-\alpha} 
 \end{align}
 
 \item The discrete Fourier transform has a downside compared to the continuous Fourier transform, as already noted in the beginning of this section. The VACF is zero at zero-frequency $ \tilde{Z}_{l=0}(z=0)=0$.  From \cref{eq:problem} also the first increment in the frequency domain is zero $ \tilde{\xi}_{l=o}(z=0)= 0$. Due to \cref{eq:fouriertrans} also the following relation holds:
 \begin{align}
   \tilde{\xi}_{l=o}(z) = \sum_{k=0}^{M-1} \xi_k e^{0} \Delta t = \Delta  R_{M} \label{correction}
 \end{align}
$\Delta R $ is the distance between the starting point and the position of the particle. Therefore, the particle would travel after $M$ steps back to its initial position. The effect on the ensemble averaged mean square displacement can be seen in \cref{fig:6}. Instead, the zero-increment in the frequency domain is calculated as follows:
\begin{align}
 \tilde{\xi}_{l=o} = \mathcal{N}(0,\sqrt{2 K_{\alpha} (M \Delta t)^\alpha})
\end{align}
\end{enumerate}




\begin{figure}
  \subfigure[Ensemble MSD without the correction introduced in \cref{correction}]{
  \includegraphics[width=0.5\textwidth]{./data/nocorrectionmsd.png}
  \label{fig:6}}
  \subfigure[Ensemble MSD with correction introduced in \cref{correction}. The side of the red bar indicates the threshold for the remaining increments for $M=2n$]{
  \includegraphics[width=0.5\textwidth]{./data/withcorrection_nocutoff.png}
  \label{fig:5}}
\end{figure}
This equation would be correct if we assumed fractional Brownian motion to be a Markovian process, which certainly is not the cause. This is also the reason why M have been chosen to be bigger than n. The presumption is, that the impact of the approximation would be negligible with increasing distance to $\Delta R_{M}$ and negligible at $\Delta R_{n}$. The impact on the ensemble averaged MSD can be seen in \cref{fig:5}. This can be thought of as a finite-time correction.

 %\item Laut dem Davies Harte Algorithmus wird außerdem das n-te Inkrement im Frequenzraum %umgeändert:
 %\begin{align}
 %\eta_{fbr_{g=n}} =\sqrt{Re(Z_g 2 n)} \mathcal{N}(0,1) 
 %\end{align}
 % Noch nicht verstanden warum!!
\end{comment}
\subsubsection{Lowen Algorithm}
\begin{table}[h]
 \begin{framed}
\begin{enumerate}
 \item Compute the auto-covariance function $R^{\xi}_n$ of a periodic stochastic process $\xi_n$:
 \begin{align}
  R^{\xi}_n=
  \begin{cases}
   \frac{1}{2}\left[1-\left(\frac{n}{N}\right)^{\alpha} \right]  & \text{ for    } 0 \leq n \leq M \\
   R^{\xi}_{2M-n}  & \text{ for    } M \leq n \leq 2M 
  \end{cases}
 \end{align}
 \item Transform the auto-covariance function via FFT. The result is called the spectral density of the stochastic process $\xi_n$:
  \begin{align}
   S^{\xi}_k= \mathrm{FFT}(R^{\xi}_n;k)
  \end{align}
 \item Calculate $\tilde\xi_k$ the Fourier transform of the stochastic process $\xi_n$:
 \begin{align}
  \tilde\xi_k=
  \begin{cases}
     0  & \text{ for    } k=0 \\    
     \exp(i \theta_k) \eta_k \sqrt{S^{\xi}_k}  & \text{ for    } 0 \leq k \leq M \\
     \eta \sqrt{S^{\xi}_k}  & \text{ for    } k = M \\
     \tilde\xi^{*}_{2M-k} & \text{ for    } M \leq k \leq 2M 
  \end{cases}
 \end{align}
 $\{*\}$ denotes the complex conjugate, $\theta_k$ is a random phase uniformly distributed  in $(0,2\pi]$. $\eta_k$ is a random Gaussian variable with zero mean and variance 1 [$\eta_k\sim \mathcal{N}(0,1)$].  
 \item Perform the inverse Fourier transform on $\tilde\xi_k$ and use the first half of the resulting stochastic process $\xi_n$ multiplied by a factor:
 \begin{align}
  \xi_n&=\frac{\mathrm{FFT}^{-1}(\tilde\xi_k;n)}{2M} \\
  B^{\alpha}_n&=  \sqrt{2 K_{\alpha} M^{\alpha} \Delta t^{\alpha}} (\xi_n- \xi_0)  \qquad \qquad \text{for} \quad 0 \leq n \leq M
 \end{align}
\end{enumerate}
\end{framed}
\caption{The table shows Lowen's fBm-generating algorithm \cite{Lowen1999}.}
\label{Lowenalgorithm}
 \end{table}
 
 An algorithm by \citet{Lowen1999} was implemented. Lowen's algorithm claims to be both fast $(\mathcal{O}(NlogN))$ and exact. However, our implementation shows not to be exact, which is shown in the analysis part. It starts with a auto-covariance function $R^{\xi}_n$. Its second derivative yields the auto-covariance of discrete time fGn described by \cref{autocovfgn}. $R^{\xi}_n$ can be thought of as an auto-covariance function of a stationary periodic version of fBm. Lowen's algorithm is described in \cref{Lowenalgorithm}. Let's check the auto-covariance function of $B^{\alpha}_n$ resulting from the algorithm: 
\begin{align}
  & Cov[B^{\alpha}_n,B^{\alpha}_m]= 2 K_{\alpha} \Delta t^{\alpha} N^{\alpha} \langle (\xi_n- \xi_0) (\xi_m- \xi_0)\rangle \\
 &=  2 K_{\alpha} \Delta t^{\alpha} N^{\alpha}\langle\xi_n \xi_m\rangle -\langle \xi_0 \xi_m \rangle - \langle \xi_0 \xi_n\rangle +\langle \xi_0^2\rangle \\ 
 &= K_{\alpha} \Delta t^{\alpha}[n^{\alpha}-2(m-n)^{\alpha}+m^{\alpha}]\qquad \qquad \qquad \text{ for} \qquad n < m
\end{align}
The auto-covariance function indeed satisfies the condition for fBm with variance similar to \cref{diffusionvariance}. In step 3 the phase and amplitude of the Fourier transform  $\xi_m$ were chosen to be random  as suggested in \cite{Timmer1995}. The second derivative of $R_{\xi}(n) $ is positive. $R_{\xi}(n) $ results in a periodic function with non-negative curvature. Its Fourier transform $S^{\xi}_k$ is, real, symmetric  and non-negative for all k. $S^{\xi}_k$ is then a valid power spectral density function of the discrete-time periodic process $\xi_n$ with period $2M$ and  $R^{\xi}_n$ its valid auto-covariance function \cite{Lowen1999}. This algorithm is actually using the property of Brownian scaling \cref{Brownianscaling} to generate a realisation of fBm  with non-negative auto-covariance function. 
\subsubsection{Davis-Harte Algorithm}
\begin{table}[h!]
 \begin{framed}
\begin{enumerate}
 \item Compute the auto-covariance function $R^{\xi}_n$ of a periodic stochastic process $\xi_n$:
 \begin{align}
  R^{\xi}_n= 
  \begin{cases}
    K_{\alpha} \Delta t^{\alpha}\left[(n-1)^{\alpha}-2n^{\alpha}+(n+1)^{\alpha}\right] & \text{ for    } 0 \leq n \leq M \\
   R^{\xi}_{2M-n}  & \text{ for    } M \leq n \leq 2M 
  \end{cases}
 \end{align}
 \item Transform the auto-covariance function via FFT. The result is called the spectral density of the stochastic process $\xi_n$:
  \begin{align}
   S^{\xi}_k= \mathrm{FFT}(R^{\xi}_n;k)
  \end{align}
 \item Calculate $\tilde\xi_k$ the Fourier transform of the stochastic process $\xi_n$:
 \begin{align}
  \tilde\xi_k=
  \begin{cases}
     \sqrt{2 S^{\xi}_k M}(\eta_k) & \text{ for    } k=0 \\    
     \sqrt{ S^{\xi}_k M}(\eta_k+i \eta_k)  & \text{ for    } 0 \leq k \leq M \\
     \sqrt{2 S^{\xi}_k M}(\eta_k)  & \text{ for    } k = M \\
     \tilde\xi^{*}_{2M-k} & \text{ for    } M \leq k \leq 2M 
  \end{cases}
 \end{align}
 $\{*\}$ denotes the complex conjugate, $\eta_k$ is a random Gaussian variable with zero mean and variance 1 [$\eta_k\sim \mathcal{N}(0,1)$].  
 \item Perform the inverse Fourier transform on $\tilde\xi_k$ and use the first half of the resulting stochastic process $\xi_n$:
 \begin{align}
  \xi_n&=\frac{1}{\sqrt{2 M}} \mathrm{FFT}^{-1}(\tilde\xi_k;n) \qquad \text{for} \quad 0 \leq n \leq N
 \end{align}
 \item perform the cumulative sum on the increments:
 \begin{align}
  B^{\alpha}_n=\sum^n_{j=0} \xi_j \qquad \qquad \qquad \qquad \text{for} \quad 0 \leq n \leq M
 \end{align}
\end{enumerate}
\end{framed}
\caption{The table shows Davis-Harte fBm-generating algorithm \cite{DAVIES1987}.}
\label{Davies_harte-algorithm}
\end{table}
Davis-Harte algorithm \cite{DAVIES1987} is related to Lowen's Algorithm. It is also based on a FFT. The author claims the algorithm to be exact and its performance to scale with the length of the trajectory as $(\mathcal{O}(NlogN))$ . However, in contrast to Lowen's algorithm, it is based on the covariance function of fGn described by equation \cref{autocovfgn}. Thus, it actually generates the increments of fBm. The  algorithm is shown in \cref{Davies_harte-algorithm}. 
\subsubsection{Accuracy Analysis}
\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{./data/timevsensambenew.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{Comparison of MSD between time-average, ensemble-average over $N=1000$ trajectories with trajectory length $M=2000$ (Cholesky: $M=300$) and  $\alpha=0.5$ for four algorithms. Cyan coloured line: Davis-Harte with $k=0.1$, red coloured: Cholesky $k=1$, green coloured: Naive $k=10$, blue colour Lowen $k=100$. }
  \label{fig:4}
\end{figure}
\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{./data/changeintimenew.png}
\caption{The plot show ensemble-averaged MSDs for forward time and backward time over $N=2000$ (Cholesky: $M=300$) trajectories with trajectory length $M=1000$  $\alpha =0.3$,  brown coloured line: Davis-Harte with $k=0.1$, red coloured: Cholesky $k=1$, green coloured: Naive $k=10$, blue colour Lowen $k=100$. All backward trajectories are cyan coloured}
\label{changeintime}
\end{figure} 
The algorithms were implemented in Python and C++. For the C++ implementation, a wrapper to Python was added. All algorithms were analysed by an analysis class. The C++ implementation is using the FFTW library for the Fast Fourier Transform \cite{FFTW} and Mersenne-Twister (gsl\texttt{\textunderscore}rng\texttt{\textunderscore}mt19937) \cite{Matsumoto1998} as the random number generator. Python implementations were developed beforehand and only serve as a reference. Python uses the numpy.fft library for the Fast Fourier Transform and also the Mersenne-Twister random number generator.\par
Insights of stochastic algorithms can be obtained by analysing observables. Observables of a stochastic process are generally averaged values. The motivation for fBm was its power law behaviour of the MSD. Therefore, it is reasonable to analyse first the MSD. It can be calculated as a ensemble- or time-average. A difference in time- and ensemble-average would show a violation of ergodicity. A comparison of all four implemented algorithms can be seen in \cref{fig:4}. Here, $\Theta=\sqrt{2K_\alpha \Delta t^{\alpha}}$ is going to be the scale defining quantity in space. The MSD is displayed in $\Theta^2$. MSDs for the algorithm are scaled with $k=0.1,1,10,100$ for Davis-Harte, Cholesky, Naive, Lowen, respectively for a better visualisation. The theoretical scaled MSD $\delta r^2 (t)=2 K_\alpha k t^{\alpha}$ are displayed as solid black lines. All algorithm show good accuracy between ensemble and time averaged MSD, besides for long lag times for the time-averaged MSD due to decreasing statistics. The naive algorithm tends to result in too small MSDs for small lag times particularly for small $\alpha$, which is going be shown later on. This is caused by the finite number of samples in the discrete Fourier transform. In the following figures all MSD plots are ensemble averages.\par Secondly, time-reversibility was checked. FBm is an equilibrium process and thus should be time reversible  \cite{Horvai2007}. A time reversed trajectory can be defined as:
\begin{align} \label{backward}
 \overleftarrow{B}^{\alpha}_n=B^{\alpha}_M-\sum^M_{j=0} \xi_{M-j}
\end{align}
In \cref{changeintime}  MSDs of normal fBm and reversed time fBm described in \cref{backward} are plotted with the previously introduced scaling parameter $k$ for better visualisation. No difference can be seen. Thus all algorithm generate an equilibrium process. $\alpha$ had been chosen to be $0.3$. Thereby the naive algorithm has an even stronger deviation from the desired power law because of the problem of the finite number of samples in the discrete Fourier transform. A strong influence of $\alpha$ on the accuracy of MSD for the naive algorithm is suspected. Hence, the influence of $\alpha$ on the MSD accuracy was studied next. The influence of $\alpha$ on the MSD for all four algorithms is shown in \cref{alphachange}. No deviations for Lowen, Cholesky and Davis-Harte can be seen. Cholesky and Davis-Harte algorithm work also in the range of $1<\alpha<2$. 
In the limit of Brownian motion $\alpha=1$, the artefacts of the naive algorithm  vanish. Cholesky, Lowen and Davis-Harte show no deviation to the expected MSD for all $\alpha$. \par
\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{./data/alpha_changethreeneu.png}
\caption{The figure shows ensemble-averaged MSDs for all four algorithms over $N=400$ trajectories with the trajectory length $M=2000$ (Cholesky: $M=64$) and $0.01\leq\alpha\leq1.0$ (Cholesky and Davis-Harte $\alpha\leq1.38$).}
\label{alphachange}
\end{figure}
\begin{figure}[h!]
\centering
\includegraphics[width=\textwidth]{./data/scaledfunctionneu12.png}
\caption{All four plots show the scale-free form of the propagator $\mathcal{P}_{gauss}(\hat{r})$ at different times as introduced in \cref{scalefreeformfrac} as an histogram over $N=10000$ trajectories for $\alpha=0.5$ at different times $100<t<900$. The dashed line show the expected distribution.}
\label{rescaledfunction}
\end{figure}
\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{./data/nongaussianlowenalphaneu.png}
\caption{ The left figure shows the Non-Gaussian-Parameter as introduced in \cref{nongaussian2} for all four algorithms with  $N=5000$, $M=100$ and $\alpha=0.5$   averaged over $30$ non-Gaussian-Parameter with its variance displayed as an error bar.\newline
The right figure shows the Non-Gaussian-Parameter for Lowen's algorithm with  $N=5000$ and $M=100$ for various $0.1\leq\alpha\leq1.0$ averaged over $30$ non-Gaussian-Parameter with its variance displayed as an error bar.}
\label{nongaussianlowen}
\end{figure}
\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{./data/nongaussianlowenalphaneumodifed.png}
\caption{The left figure shows the MSD for various $\alpha$ in the range $0.1\leq\alpha\leq1.0$ generated by the modified Lowen algorithm with $M,N=2000$.\newline
The right figure shows the  Non-Gaussian-Parameter for the modified Lowen algorithms with  $N=5000$, $M=100$, $\Delta t = 0.1$ for various $0.1\leq\alpha\leq1.0$ averaged over $30$ non-Gaussian-Parameter with its variance displayed as an error bar.}
\label{nongaussianlowenmodif}
\end{figure}
FBms property of self-similarity can be used to plot a scale-free version of the density distribution ($\mathcal{P}_{gauss}(\hat{r})$). The scale-free version was introduced in \cref{scalefreeformfrac}. The scaled density distribution is not depended on time. Time rescaling leads to a "data collapse". In \cref{rescaledfunction}  histograms over $N=10000$ single trajectories at various times ($100\leq t \leq 1000$) were calculated and rescaled according to \cref{scalefreeformfrac}. The histograms were scaling for different algorithms w  the scaling parameter $k$ for better visualisation. For Cholesky and our algorithm no deviations from the theoretical values are obvious. For Lowen's algorithm, systematically small changes to the theoretical value can be observed. However, the distribution of fBm should stay a Gaussian for all times. As introduced in \cref{nongaussian2}, the non-Gaussian parameter ($NGP(t)$) should be zero. The Non-Gaussian parameter was plotted for $0 \leq t \leq 1000 (\leq 356 \text{ for Cholesky})$  $\alpha=0.5$ in the left \cref{nongaussianlowen}.The Naive, Davis-Harte and Cholesky algorithm perform as expected. Lowen however, shows deviations from a Gaussian distribution increasingly towards the end of the trajectory. In the right \cref{nongaussianlowen}, the influence of $\alpha$ on the non-Gaussian parameter for the Lowen algorithm was tested. For small $\alpha$, the distribution is closer to a Gaussian. In our implementation, Lowen's algorithm is not exact as claimed in \cite{Lowen1999}. A modification to the algorithm  was introduced in point 3 in \cref{Lowenalgorithm}. The modification introduces the correlation with random complex numbers generated in the rectangular representation, just like in Davis-Harte algorithm in the third point for $ 0 \leq k \leq M $. The resulting accuracy of MSD and a comparison of the non-Gaussian parameter are shown in \cref{nongaussianlowenmodif}. Modified Lowen algorithm shows no deviation in the MSD and Non-Gaussian parameter to the desired theoretical values.



\begin{comment}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{./data/profiling_length.png}
  \captionsetup{width=0.9\linewidth}
  \captionof{figure}{Scaling behaviour of computational time of both algorithms implemented in c++ and python  in respect to trajectory length $M$,for $N=1$, $t = \mathcal{O}(M log(M))$ }
  \label{fig:1}
\end{figure}
\begin{figure}[h!]
  \centering
  \includegraphics[width=\linewidth]{./data/profiling_particle.png}
  \captionsetup{width=0.9\linewidth}
  \captionof{figure}{Scaling behaviour of computational time of both algorithms implemented in c++ and python  in respect to trajectory number $N$ for $M=1000$ ,$t = \mathcal{O}(N log(N))$}
  \label{fig:2}
\end{figure}
\end{comment}
\newpage
\subsubsection{Performance Analysis}
The performance with trajectory length and number of trajectories was analysed in \cref{fig:200,fig:201}. Thereby, the very promising, in terms of exactness, Cholesky algorithm scales with $\mathcal{O}(M^3)$ with trajectory length $M$. Our application of an fBm-generating algorithm desires long trajectories. It is not reasonable to use such a slow algorithm. Even if every next trajectory with same $\alpha$ and length scales with $\mathcal{O}(M^2)$ \cite{Dieker2004}.  Modified Lowen and Davis-Harte seem also to be exact. Both scale with $\mathcal{O}(M log(M))$ due to the FFT. Lowen algorithm is even faster because it directly generates fBm. Davis-Harte algorithm generates fGn. Davis-Harte looses some performance on the cumulative summation of the increments. The performance with the number of trajectories is displayed in \cref{fig:201}. All algorithms scale linearly with the number of trajectories $N$. Cholesky algorithm has an high offset but scales then slowly with the number of trajectories . Although one should keep in mind, that the trajectory length had to be chosen $M=128$ compared to $M=1000$ for the other algorithm to get comparably small values.
\begin{figure}[h!]
  \centering
  \includegraphics[width=\linewidth]{./data/nongaussiandouble1.png}
  \captionsetup{width=1.0\linewidth}
  \captionof{figure}{Algorithmic scaling of computational time with the trajectory length $M$ for a single trajectory $N=1$. Dashed lines are algorithms implemented in C++. Solid Lines are algorithms implemented in Python.}
  \label{fig:200}
\end{figure}


 \begin{figure}[h!]
  \centering
  \includegraphics[width=\linewidth]{./data/nongaussiandouble2.png}
  \captionsetup{width=1.0\linewidth}
  \captionof{figure}{Algorithmic scaling of computational time with the number $N$ of trajectories and trajectory length $M=1000$ (Cholesky $M=128$).Dashed lines are algorithms implemented in C++. Solid Lines are algorithms implemented in Python. }
  \label{fig:201}
\end{figure}
\begin{comment}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\linewidth]{./data/profilingneu1.png}
  \captionsetup{width=0.9\linewidth}
  \captionof{figure}{a) Algorithmic scaling of computational time in respect to the amount of trajectories $N$ for trajectory length $M=1000$ , ($D=2$, $\alpha=0.5$, $\Delta t=1$) of Lowen and our own algorithm. Both implemented in  c++ and python (p). The Cholesky algorithm was implemented in python with $M=128$.\newline
  b) Algorithmic scaling of computational time in respect to the trajectory length $M$ for a single trajectory $N=1$ , ($D=2$, $\alpha=0.5$, $\Delta t=1$). Lowen and our own algorithms are implemented in c++ and python (p). Cholesky is only implemented in python (p).}
  \label{fig:200}
\end{figure}\end{comment}


\chapter{Particle Based Reaction Diffusion }
Chemical reactions are ubiquitous in nature. They describe transformations of one or several chemical substances. Transformations of chemical substances are described by formation and breaking of chemical bonds. Physically precise, theses bonds should be described quantum mechanically. Quantum mechanics is not needed for a description at cellular scales. Not to mention, that for such large systems these calculations cannot be performed. Hence, coarse-grained models for reactions at cellular scale were developed. But reactions in a broader sense can also be a transformations of one state to another one (e.g. protein changing its conformation). Biochemical reactions give rise to the complexity of life and are of key importance for processes in living cells. Indeed, Biochemistry is a whole area of research.\par Early pioneer work on reactions, by Guldberg and Waage already in 1864 \cite{Waage1986}, resulted in the law of mass action, which states the proportionality of the reaction rate to the product of concentrations for elementary molecular reactions. Thereby, spatial resolution is neglected. The system is described in terms of a concentration (well-mixed assumption). The mass action law leads to a deterministic model described by ordinary differential equations (ODEs). Quantities like reaction kinetics and number of reactants in equilibrium can be obtained. Deterministic models, however, are not resolving stochastic phenomena. Stochastic models provide a more detailed understanding of the reaction-diffusion processes. Such a description is often necessary for the modelling of biological systems, where small molecular abundances of some chemical species make deterministic models inaccurate or even inapplicable \cite{0704.1908}. Stochastic models based on the mass action law are characterised by the chemical master equation (CME). CME describes the temporal evolution of probabilities for the system to occupy each different state. The interesting topic of chemical kinetics described by CME will not be part of the elaborations. Nevertheless, for the sake of completeness, it was to be mentioned that stochastic simulations based on CME with the Gillispie algorithm \cite{Gillespie1977} are performing very efficiently. Even spatial resolutions can be achieved with simulations based on the reaction-diffusion master equation (RDME \cite{Winkelmann2016}). Still, the well-mixed assumption has to hold at least for the compartments of the RDME model. A more detailed model is given by particle-based reaction-diffusion dynamics (PBRD)\cite{Schneberg2014,Gruenert2010}. Thereby, all particles are modelled as points or spheres and are resolved in space and time. However, the size  of common biological systems surpasses computational feasibility. So further coarse graining gets necessary. Difficulties in simulations of biological systems arise on the one hand from very large systems and on the other from small molecular abundances of some chemical species. The well-mixed assumption does not hold.  A less prominent approach is a PBRD model with fractional Brownian dynamics. Fractional Brownian motion approximates the motion of a particle in a crowded biological medium. The motion of the media itself has not to be modelled explicitly. Therefore, PBRD simulations can be performed just for the relevant reacting particles. Stochastic particle-based models conventionally rely on Brownian or Langevin dynamics for the description of diffusion. Brownian dynamics was introduced in chapter 1. Langevin dynamics will not be examined explicitly. In short, it is further includes also the relaxation of particles momentum and reaches Brownian dynamics in the limit of strong damping, or at long time scales.\par
This chapter deals with some theoretical considerations on the impact of diffusion on reaction rates. The first section examines Smoluchwoski's pioneering work \cite{Smoluchowski1} on diffusion-limited reaction kinetics of a bi-molecular reaction and Erban/Chapmman extensions \cite{Erban2009} for diffusion-influenced bi-molecular reactions. Thereby, a dependence of macroscopic reaction rates and the diffusion of the particles can be seen. These results shall motivate investigations of reaction-diffusion dynamics with a different diffusion model. Along the way the law of mass action is shown to follow under certain conditions from the diffusion \cref{eq:ficks} motivated and introduced in the first chapter. These derivations further motivate both, models based on the law of mass action and PBRD models. RevReaDDy, a realisation of the latter, is then introduced and explained in the second section of this chapter.




% In the first section this law is shown to follow from the diffusion \cref{eq:ficks} motivated and introduced in the first chapter. In the process(along the way) fundamental derivations for the kinetics of a bimolecular reaction limited and influenced by diffusion are shown. Theses derivations motivate the description of chemical reactions in an concentration or particle based model. 
% 
% 
% 
% 
% Another less prominet idea 
% 
% 
% 
% 
% 
% Interesting quatenties are reaction kinetics, amount of reactants in equlibrium and spatial distirbutions. Most commonly chemical kinetics are modelled by ordinary differential equations (ODEs) based on the mass action law. Thereby any concentrations are assumed to be constant in space. 
% 
% 
% 
% 
% 
% 
% In the first section this law is shown to follow from the diffusion \cref{eq:ficks} motivated and introduced in the first chapter. In the process fundamental derivations for the kinetics of a bimolecular reaction limited and influenced by diffusion are shown. Theses derivations motivate the description of chemical reactions in an concentration or particle based model. The interesting topic of chemical reactions with concentrations based models will not be part of the elaborations. Nevertless, for the sake of completeness, it was tggggggggggggggggggggggggggggo be mentioned that concentration based models following from the chemical master equation can describe reactions with the Gillispie algorithm \cite{Gillespie1977} very efficiently. Even spatial resolutions can be achieved with compartment based chemical master equations (Reaction-Diffusion Master Equation) RDME . This chapter examines a particle based model more specifically. Both models can be further categorised into two fundamental mathematical approaches: deterministic models which are based on differential equations; and stochastic simulations. Stochastic models provide a more detailed understanding of the reaction-diffusion processes. Such a description is often necessary for the modelling of biological systems where small molecular abundances of some chemical species make deterministic models inaccurate or even inapplicable \cite{0704.1908}. Stochastic particle based models conventionally rely on Brownian or Langevin dynamics for the description of diffusion. Brownian dynamics was introduced in chapter 1. Langevin dynamics will not be examined explicitly. In short, it is further considering momentum and reaches Brownian dynamics in the limit of vanishing momentum. Fractional Brownian motion was also introduced in the first chapter. It is less frequently used for the description of diffusion in reaction diffusion models. However, in chapter three a reaction with fraction Brownian motion is studied. For fractional diffusion mass action law does not apply. Thus conventional concentration based modelswith time independed rate coefficients are no longer suitibale \cite{Berry2002}  \cite{schnell2004reaction}. After setting up the foundations a particle based simulation package with fractional Brownian motion will be introduced, which is going to be applied in chapter three for a particular enyzmatic reaction.
% 
% 
% The motivation of reaction diffusion is to combine the theory of chemical reactions and 
% normal reaction diffusion can be modelled by various models. Depending on the system one might be favourable over the other. In general two different approaches can be distinguished. Deterministic models based on differential equations and stochastic simulations. Reaction diffusion for well mixed system can even be described by a system of ODEs. Thereby any concentrations in space are assumed to be constant. Theses ODEs follow from the law of mass action and coalition theory for an ideal gas ( independent increments). They are naturally used for chemical kinetics and the amount of concentration in equilibrium. 
% 
% 

%Let mass conservation be the starting point:
\section{Diffusion Influenced Bimolecular Reaction}\label{Erban-chapman-section}
Uni- and bi-molecular elementary reactions are most relevant in nature. According to collision theory, tri-molecular elementary reactions are negligible. Diffusion is not relevant for uni-molecular reactions. It is reasonable to start our considerations on how diffusion influences chemical reactions with the Smoluchowski problem for kinetics of a bi-molecular chemical reaction in solution. One particular area of research on which the Smoluchowski relation had a significant impact in the last few decades is biology. This is unsurprising as a vast number of biomolecular systems involve dilute and minute diffusing molecular populations undergoing continuous reaction. Understanding how these biological systems operate is complicated and is in itself a whole field of research; systems biology. The Smoluchowski result has provided a very powerful tool for theoretical investigation of microscopic biochemical reaction-diffusion processes \cite{Flegg}. It was extended by P. Debye in 1942 to add intermolecular forces. However, especially in biological systems Brownian motion do not apply for all time-scales. These environments exhibit very often anomalous diffusion, which can be addressed by fBm. 
\par
The following derivation shall give the kinetics of a simple model for a bi-molecular reaction and motivate a particle-based simulation scheme.
The reaction scheme for a bi-molecular reaction with reactants A and B associate into a complex AB with a rate $k^{+}_{\mathrm{d}}$ and decay into A and B with a rate $k^{-}_{\mathrm{d}}$. The chemical reaction can be written as:
\begin{align}\label{reactionscemebi}
\text{\ch{A + B <=>[ $k^{+}_{\mathrm{d}}$ ][ $k^{-}_{\mathrm{d}}$ ] AB }}
\end{align}
Free diffusion of particle A and B with the diffusion constants $D_A$ and $D_B$, respectively, are assumed. Further no interactions between them are present. In fact, this problem can be described by a modified version of the diffusion \cref{eq:ficks} motivated in the first chapter.
The joint concentration field $\rho_t(\bm{r}_A,\bm{r}_B)$ for a bi-molecular system in a solution obeys:
\begin{align}
 \frac{\partial \rho_t(\bm{r}_A,\bm{r}_B)}{\partial t}=(D_A \nabla^{2}_{A}+D_B \nabla^{2}_{B}) \rho_t(\bm{r}_A,\bm{r}_B) \label{smolubi}
\end{align}
The complexity of the problem can be reduced by substituting the positions of the particles A and B with their relative distance $\bm{r}=\bm{r}_A-\bm{r}_B$. It is convenient to introduce even further substitutions:
\begin{align}
 D= D_A+D_B \qquad \qquad \bm{R}=\frac{D_B \bm{r}_A+ D_A \bm{r}_B}{D_A+D_B}
\end{align}
the Laplace operator in terms of new coordinates result in:
\begin{align}
\nabla^{2}_{A} = \left( \nabla_r+\frac{D_B}{D} \nabla_R \right)^2 \label{eq:10}\\
\nabla^{2}_{B} = \left( \nabla_r+\frac{D_A}{D} \nabla_R \right)^2 \label{eq:11}
\end{align}
By inserting \cref{eq:10}  and (\ref{eq:11}) in \cref{smolubi} the following result can be obtained:
\begin{align}
 \frac{\partial \tilde{\rho}_t(\bm{r},\bm{R})}{\partial t}=\left(D \nabla^{2}_{r}+\frac{D_B D_A}{D_A+D_B}\nabla^{2}_{R}\right) \tilde{\rho}_t(\bm{r},\bm{R})
\end{align}
This equation describes two independent diffusion processes, one in the coordinate $\bm{r}$ and one in the coordinate $\bm{R}$. The solution can be obtained by the product ansatz $\tilde{\rho}_t(\bm{r},\bm{R})=\rho_t(\bm{r})q_t(\bm{R})$. Integration over $\bm{R}$ results in:
\begin{align}
\frac{\partial \tilde{\rho}_t(\bm{r},\bm{R})}{\partial t}=D \nabla^{2}_{r} \rho_t(\bm{r}) +\frac{D_B D_A}{D_A+D_B}   \int_{\partial V} \nabla_{R} q_t(\bm{R}) d \bm{a}
\end{align}
In the previous equation the stokes theorem was applied. The integral in the second term is zero due to conservation of probability. The problem is isotropic, hence $r=|\bm{r}|$ and $\nabla^{2}_{\bm{r}}=\left(\partial_r+\frac{2}{r}\right)\partial_r$. The equation reduces to the one-dimension form of the continuity \cref{continuity} without any production term:
\begin{align} \label{smoluchwoskionedimension}
\frac{\partial \rho_t(r)}{\partial t}=-\left(\frac{\partial}{\partial_r}+\frac{2}{r} \right) j_t(r) \qquad \qquad j_t(r)=D \frac{\partial\rho_t(r)}{\partial_r}
\end{align}
 The stationary distribution satisfies:
\begin{align}
 -\left(\frac{\partial}{\partial_r}+\frac{2}{r} \right) j^{s}(r)&= 0\\
 \frac{d j^{s}(r)}{j^{s}}  &=- \frac{2}{r} dr\\
 j^{s}(r)&=A r^{-2}\\
 \rho^s(r)&=\rho^s(\sigma)- \frac{\int_{\sigma}^{r} j^{s}(r')dr'}{D}=\rho^s(\sigma)+\frac{A}{D}\left(\frac{1}{r}-\frac{1}{\sigma}\right)
\end{align}
Here, $\sigma$ is defining a distance between particle A and B. It is going to be the scale defining quantity in space. For particles A and B closer than $\sigma$ instantaneous reactions occur and the joint concentration equals zero ($r\leq \sigma \Rightarrow \rho_t(r \leq \sigma)=0$). Now, let's assume only a single molecule B being at the position $r=0$ and a constant concentration of particles A at infinity ($\rho_t(r \rightarrow \infty)=c_A$). The frame of reference is the B particle. This approximation, where the distribution of particle A around a single particle B is studied without any B particles, besides the one in the origin, should also be true for a low concentrations of B particles relative to A particles ($c_B\gg c_A$). Two or more B particles in proximity would disturb the concentration profile. The solutions for $\rho^{s}(r)$ and $j^{s}_t(r)$ for the upper boundary conditions are:
\begin{align}
 \rho^{s}(r)=c_A \left(1-\frac{\sigma}{r}\right) \qquad \qquad j^{s}(r)&=-D \sigma c_A r^{-2}
 \label{smoluchwoskiproblem}
\end{align}
With \cref{reactionscemebi} in mind it should be clear, that the production of $c_{AB}$ originates from the flux of particles at $\sigma$. The production of the concentration of $c_{AB}$ is then: 
\begin{align}
 \frac{d c_{AB} }{dt}=4 \pi \sigma D c_A c_B \label{difkinetics}
\end{align}
Along the way several assumptions were made:
\begin{itemize}
  \item The system can be described by a diffusion constant which is independent of the time and and position. 
  \item No interaction between particles are present (ideal gas).
  \item The system has a constant background concentration of A particles $\rho_t(r \rightarrow \infty)=c_A$.
  \item The dynamics are stationary.
  \item The reaction is limited by diffusion. Since, reactions occur instantaneously at $r=\sigma$. 
\end{itemize}
Still, the solution gives the kinetics for a simple bi-molecular system. It is consistent with collision theory, which states that the collision frequency is proportional to the concentrations of the colliding particles. Pioneer work on reaction kinetics by Guldberg and Waage already in 1864 \cite{Waage1986} resulted in the law of mass action which states for elementary uni- and bi-molecular reactions, the proportionality of the reaction rate ($r_f$) to the concentration.
\begin{align} \label{lawofmass}
 r_f=k_f c_A c_B
\end{align}
This equation provides the basis for a description of reaction kinetics in terms of ordinary differential equations (ODEs) like \cref{difkinetics}.\par
Smoluchowski's problem can be, in fact, generalised for reactions to occur with a finite microscopic rate $\lambda_{+}$ within a radius $\sigma$, derived by \citet{Erban2009}.  However, as a small remark, the microscopic rate has to be distinguished from the macroscopic rate. As an example microscopic rates are related to the Kramers problem, describing the time dependence of a particle passing a potential barrier e. g. commonly in biology protein binding / unbinding. The generalized problem can be described similarly to Smoluchwoski's problem \cref{smoluchwoskionedimension}  with an production term  continuity  \cref{continuity} :
\begin{align}
\frac{\partial}{\partial t} c(\bm{r},t))=- \nabla J(\bm{r},t)- \lambda_+ c(\bm{r},t) \mathrm{H}(\sigma)
\end{align}
Here, $\mathrm{H}(\sigma)$ is the Heaviside step function. The derivation of a  stationary solution of the second-order ODEs analogously to the Smoluchowiski problem can be found in the appendix \ref{Erban-Chapmann}. The solution shows again the possibility of describing the production with a macroscopic reaction rate $k_{+}(\kappa, \sigma)$:
\begin{align} \label{kalphaerbanchepmann}
k_{+}=4 \pi D \sigma \left( 1-\frac{1}{\sigma \kappa} \tanh{\sigma \kappa}\right)
\end{align}
Here, $\kappa=\sqrt{\lambda_+/D}$ and $1/\kappa$ can be intuitively interpreted as the penetration length of A particles into the shell with distance $\sigma$ around B particles. The scenario in two dimensions is visualised in \cref{fig:model-reactions}. The law of mass (\cref{lawofmass}) still holds for a bi-molecular reaction not only in the diffusion limit. but also for reactions occurring with a certain microscopic rate, under the well-mixed assumption and normal diffusion.  ODEs for the system can be formulated. There solutions give the kinetics and concentrations in equilibrium, but no information on the spatial distribution are contained.
\begin{figure}[h!]
\captionsetup{singlelinecheck=off}
\centering
\includegraphics[width=\textwidth]{./data/smoluchowskierban.png}
  %\captionsetup{width=\linewidth}
\caption{Density distribution from \cref{erbanchapmanradial1,erbanchapmanradial} for a bi-molecular reaction from the Erban-Chapman derivation for three scenarios:}
\begin{small}
\begin{enumerate}
  \item The microscopic reaction limit for $\lambda_{+} =0.0$ displayed as a green solid line
  \item An intermediate scenario with $\lambda_{+} =2d/\sigma^2$ displayed as a blue solid line.
  \item Smoluchwski's result for diffusion-limited reactions   $\lambda_{+}=\infty $.
\end{enumerate}
\end{small}
  \label{fig:diffusion_limit-Erban-Chapmann-figure}
\end{figure}

\par
For the generalised problem with a microscopic rate $\lambda_{+}$, a diffusion- and microscopic reaction-limit can be shown. For $\lambda_{+} \rightarrow \infty $ reactions occur immediately and the diffusion-limit is reached. If  $\lambda_{+} \ll D/\sigma^2$ a Taylor expansion of the Tangens Hyperbolicus in \cref{kalphaerbanchepmann} is given by:
\begin{align}
\tanh{x\rightarrow 0} \approx x-\frac{x^3}{3}
\end{align}
and \cref{kalphaerbanchepmann} can be approximated as:
\begin{align}
 k_{+}=\frac{4 \pi \sigma^3 \lambda_{+}}{3}
\end{align}
The macroscopic reaction rate no longer depends on diffusion but solely on the microscopic reaction rate. The stationary distributions for both limits and an intermediate scenario are plotted in \cref{fig:diffusion_limit-Erban-Chapmann-figure}.\par
The previous elaborations show that macroscopic reaction rates dependent on diffusion for bi-molecular reactions. For simple reaction-diffusion systems the evolution and the stationary distribution of the density distribution can be obtained by solving Smoluchwoski's equation (PDE). For the bi-molecular reaction the law of mass action could be seen to follow for spatial homogeneity. Then reaction kinetics can be described for easy systems in terms of ODEs. Nevertheless, for complex systems often no closed solution is known. Further, for small molecular abundances of some chemical species deterministic models get inaccurate or even inapplicable. Stochastic models are necessary. Via chemical master equations (CMEs) and reaction-diffusion master equations (RDMEs) analytical stochastic results can be obtained. Deduced from the Master equation also stochastic simulations based on Monte Carlo methods, like the prominent Gillispie algorithm \cite{Gillespie1977}, can be performed. This chapter, however, aims to introduce PBRD. The implementation of a PBRD simulation introduced in the next section follows the theoretical description of reactions with microscopic reaction rates within a reaction radius in this section.
% 
% 
% 
% Ab hier überleitung zu dann zur onvection-diffusion equation als motivation für simulations (ODE,PDEs, CME, RDME, PBRD, fractional PBRD). Letzteres analytic solution nicht einfach Fractional calculus, fractional Fokker-plank, frachtional master equation.
% 
% 
% 
% 
% 
% 
% 
% 
% It can also be interpreted as the production term in the continuity equation. In literature this equation is referred to as the convection-diffusion equation:
% \begin{align}
%  \frac{\partial \rho_t(r)}{\partial t}=-\left(\frac{\partial}{\partial_r}+\frac{2}{r} \right) j_t(r) + R \label{convenctiondiffsuion}
% \end{align}
% with $R$ the production term. For simple systems analytical solutions for theses partial derivative eqaution (PDEs) exist. 
% 
% 
% For easy problems analytical solutions to spatial distribution can be obtained by solving the convection diffusion \cref{convenctiondiffsuion}. \newline
% 
% 


% A particle based model for diffusion is Brownian motion introduced in the first chapter. Thereby similar to the setup of the previous elaborations by Erban and Chapman  particles can react within a certain distance $\sigma$ with a certain microscopic reaction rate $\lambda$. These calculation most 
% 
% Determinitic:
% Then Smoluchowski. (then gas theory wiki, maybe aurilius and kramers problem and simulations of proteins for determination of rates in reaction). back mass conservation with  production term. Then erban chapman. Then no diffusion (or diffusion time independ (and in-cooperated in marcoscopic rate.)). constant concentration (again mass action from gas theory)  . concentration  based models (ODEs) and solving . Then CME Then compartment based CME. 
% 
% Then stochastic simulations, stochstic cme. stochstic compatment based cme. stochastic particle based simulations smoluchawoski/diffsuion equation to Fockerplank. (fluctuations / dissipation ) theorem.
% 
%  
% 
% 
% 
% 
% 
% 
% Deterministic models have their origin.  
% 
% 
% stationary values. kinetics. spatial distribution of reactants. 
% 
% What are interesting observables. Solutions in dynamical equilibrium reaction rates rate equtaions ( assumption rate is independent of time. not nesesarilly true.  chemical equlubrium. Mass action. order of reaction. Smoluchowski. Chemical master equation. quantum physical -> bonds between reactants for example electrons involved.
% \section{chemical reactions}
% With no information on 
% The classical theory of reaction 
%  
% 
% 
% 
% 
% 
% 
% 
% In biological systems, phenomena often depend on stochastic fluctuations. Deterministic models often are often inaccurate or even not applicable at all. 
% (von franks Vortrag das Bild mit den unterschiedlichen Methoden zur genererieung von Reactiondiffusions systemen). 
% This chapter is going to discuss particle based reaction diffusion. Particle based reaction diffusion is going to be put in relation to different reaction diffusion studying methods.  
% Analytical solutions for resulting ordinary differencial equation exist under certain conditions like Quasi-Steady-State assumption or equilibrium assumption. In any case the mass action law is assumed. For fractional diffusion mass action law does not apply. Thus concentration based models had been upgraded by time depended rate coefficients \cite{Berry2002}  \cite{schnell2004reaction}
% \section{Smoluchowski}
% \section{Erban Chapmann}
\section{RevReaddy with fBm} 
RevReaDDy is a PBRD tool developed by Christoph Fröhner whithin his PhD project under supervision of Frank Noé. It is not published. Many modification to the tool had to be done in the process of this thesis. ReRreaDDy is based on the simulation package ReaDDy by Johannes Schöneberg and Frank Noé \cite{10.1371/journal.pone.0074261}. Reaction-diffusion dynamics of all particles can be resolved in space and time. Particles are modelled as spheres with possible particle interaction potentials. The tool aims to bridge the gap between molecular simulation and CME/RDME simulations. It is written in C++. However, the user can setup up and simulate the desired reaction scheme in Python via a Python binding. Particle types with a specific radius and diffusion constant can be defined. Particles of a predefined particle type can be placed anywhere into a simulation box with variable box size and periodic boundary conditions. A desired simulation length and width of the time step have to be set. Conventionally particles propagate by Brownian Dynamics. In the process of the thesis also a fractional Brownian motion integrator with the circulant method by Davis-Harte \cite{Dieker2004}  and Lowen \cite{Lowen1999} was implemented. For Brownian Dynamics, potentials with two different potential types, Lennard Jones and soft repulsion, can be introduced to act in-between participles and between fixed geometries in the simulation box and particles. Thereby, a temperature has to by defined. Particles can be e.g limited to diffuse on a surface by a potential. It can be chosen from various reaction types to affect the particle types. For uni-molecular reactions like conversion \ch{A <=>[ $k$ ][ $k'$ ] B}, annihilation \ch{A -> [ $k$ ] $\emptyset$}, decay \ch{$A$ ->[ $k$ ] $B+C$} the probability that one particle undergoes a reaction within the timestep ($\Delta t$) is simply approximated as:
\begin{align} \label{propabilityreaction}
 P(n)=1- \exp[-\lambda \Delta t n] \approx \lambda \Delta t n \qquad \text{for} \qquad P(1)\ll 1
\end{align}
Here, $n=t/\Delta t$. A more sophisticated algorithm, which draws the reaction time from the correct distribution is the Gillispie algorithm \cite{Gillespie1977}. It could by implemented into RevReaDDy as an improvement. For such reactions,  microscopic reaction rates $\lambda$ are independent of the position.
\begin{figure} 
  \centering
  \includegraphics[width=0.7 \textwidth]{./data/schemeforreacions1.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{The Figure shows a visualisation of a bi-molecular reaction between particle A and B in RevReaDDy. Particle B are coloured blue and particle A are coloured red. }
  \label{fig:model-reactions}
\end{figure}
\par
For a decay reaction a weighting factor and reaction distance shall be defined. They determine how far each of the particles are placed from the previously existing complex. With the waiting factor equals zero, particle A is placed at the position of the pre-existing complex and particle B is placed with a uniform distribution in the sphere with reaction radius $\sigma$. For bi-molecular reactions like the enzymatic reaction with complex building \ch{$A + B$ <=>[ $k$ ][ $k'$ ] $A + C$} or fusion \ch{$A + B$ ->[$k$] C} relative positions of the reactants are important for the reaction to take place. Analogous to the setup up of Erban and Chapman in \cref{Erban-chapman-section} a microscopic reaction rate $\lambda$ within a reaction distance $\sigma$ have to be defined. If the reactants come closer than $\sigma$ a reaction takes place with probability $P= \lambda \Delta t$ during $\Delta t$. The problem is visualised in \cref{fig:model-reactions}. Thereby the time step cannot by chosen arbitrarily large. The mean square displacement for Brownian motion in three-dimensions is given as $\delta r^2(\Delta t)= 6D \Delta t$. The mean displacement during one time step has to be a lot smaller than the squared penetration length $\delta r^2(\Delta t)\ll 1/\kappa^2$ . Otherwise differences between the time of particles staying within a radius $\sigma$ to another particle would differ significantly in comparison to $\Delta t \rightarrow 0$. Thus, also the macroscopic reaction rates would become less accurate. For fractional Brownian motion with $\alpha<1$ the effect increases. A variety of observables are provided in RevReaddy, which are written into HDF5 files \cite{hdf5} during the simulation. Possible observables are: Acceptance rate, energy, mean square displacement, particle number, radial distribution functions, number of reactions, increments and positions. Observables can mostly be defined to consider any particle type over any period in time. 

\chapter{An Enzymatic Reaction With Fractional Brownian Motion}
\begin{comment}
Enzymes are large biological molecules, mostly proteins. Metabolic processes in cells rely vitally on enzymes. They help to break down large nutrient molecules like carbohydrates, fats and proteins during in the process of digestion. Other enzymes contrariwise help forming large and complex molecules from smaller once. Enzymes are involved in storage and release of energy, processes of respiration, vision, muscle contraction, transmission of nerve impulses. In fact biochemical reactions are controlled mainly by enzymes. In general they act as catalysts by lowering the activation energy. As stated by the Arrhenius law the activation energy is than increasing the reaction rates. The speed of reactions is typically increased by a factor of $10^6-10^{14}$. 
\end{comment}
The biochemical reactions taking place in cells, though thermodynamically favourable, are in most cases very slow if left uncatalysed. For example, the spontaneous cleavage of a peptide bond would take 400 years at room temperature and phosphomonoester hydrolysis, routinely breaking up ATP to release energy, would take about a million years in the absence of the enzymes that shuttle that reaction along \cite{Wolfenden2001}. They have a defined amino acid sequence and a three-dimensional structure. The specific three-dimensional structure contains an active site for a substrate molecule to bind and orient and a catalytic site to reduce the chemical activation energy. Usually, an enzyme molecule has only one active site, and the active site fits with one specific type of substrate. So enzymes mostly have a high specificity for a particular type of reaction.  After reaction takes place the product is released. The enzyme is free to start the reaction circle with a new substrate. Many reversible intermediate states can be present in the reaction mechanism. A simple representation of the mechanism with two complex intermediate states can be written as:
\begin{align} \label{eq:enyzmescheme}
\ch{S + E <=>[$ k_1 $][$ k'_1 $] ES <=>[$ k_2 $][$ k'_2 $] EP<=>[ $k_3 $][$ k'_3 $]P + E} ,
\end{align}
$k$ are the forward rates and $k'$ the backward rates. $\mathrm{S}$ and $\mathrm{P}$ are substrates and products, respectively. $\mathrm{ES}$ and $\mathrm{EP}$ are intermediate complexes. By the law of mass action, ODEs can be formulated but often no closed solution exists.\par
The focus of this chapter is to study the kinetics and spatial distribution of the Michaelis-Menten mechanism, an even simpler mechanism, in the presence of normal and fractional Brownian motion. Monte Carlo simulations with anomalous diffusion modelled by a random walk between immobile obstacles were performed by \citet{Berry2002, Schnell2004}. An overview on stochastic modelling of in vivo reactions was given by Turner \cite{Turner2004}. Recently, first passage time simulations with fBm were performed by \citet{Jeon2014}. A Michaelis-Menten mechanism with fractional Brownian motion has not been studied yet.
\section{Michaelis-Menten (MM) kinetics}
Leonor Michaelis and Maud Menten  proposed in 1913 a mathematical model for enzyme kinetics. Their most important contribution was to assume an enzyme-substrate to be present \cite{michaelis1913kinetik}. In their honour, it is also called Michaelis-Menten complex. A simpler version of \cref{eq:enyzmescheme} was proposed as the Michaelis-Menten mechanism:
\begin{align} \label{eq:michaelismechanism}
\ch{S + E <=>[$ k_+ $][$ k_- $] ES -> [ $k_c $]P + E}
\end{align}
 The backward reaction rate, from products and enzymes to complexes, was assumed to be negligible. They postulated the relation between the reaction velocity, formation of products, and the concentration of substrates. This relation is captured by the so called Michaelis-Menten equation:
\begin{align} \label{michaelis-menten-equation}
 v=\frac{v_{max} c_s}{K_M+ c_s}
\end{align}
$v_{max}$ is the maximum reaction velocity. The Michaelis constant $K_M$ is the substrate concentration with $50 \%$ of maximum velocity and $c_S$  is the concentration of the substrate. A derivation of the Michaelis-Menten equation was done by \citet{Briggs1925} in 1925, assuming the mass action law, mass conservation and a quasi-steady state approximation (QSSA). It states that after a negligible initial transition regime ($t \ll t_c$) the concentration of the complex varies slowly as if in a quasi-steady state ($dc_{ES}/dt=0$). A set of differential equations can be formulated as a result of mass conservation and the mass action law:
\begin{align}
\frac{dc_S(t)}{dt} &= k_{\mathrm{-}} c_{ES}(t)-k_{\mathrm{+}} c_E(t) c_S(t),\\
\frac{dc_{ES}(t)}{dt} &=  - k_{\mathrm{c}} c_{ES}(t) -k_{\mathrm{-}} c_{ES}(t)+k_{\mathrm{+}} c_E(t) c_S(t), \label{quasisteadymichaelis} \\
\frac{dc_P(t)}{dt} &= k_{\mathrm{c}} c_{ES}(t)  \label{first}, \\
\frac{dc_E(t)}{dt} &= k_{\mathrm{c}} c_{ES}(t)+k_{\mathrm{-}} c_{ES}(t)-k_{\mathrm{-}} c_E(t) c_S(t),
\end{align}
with a quasi-steady-state approximation, one can reduce \cref{quasisteadymichaelis} to: $ k_{\mathrm{+}}c_E(t) c_S(t)=k_{\mathrm{-}}c_{ES}+k_{\mathrm{c}}c_{ES}(t)$. A Rearrangement of this equation results in the Michaelis-Menten constant:
\begin{align}
 K_M=\frac{k_{\mathrm{-}}+k_{\mathrm{c}}}{k_{\mathrm{+}}}=\frac{c_E(t) c_S(t)}{c_{ES}}. 
\end{align}
The mass conservation law yields: $c_E(t)=c_{E_0} -c_{ES}(t)$. After inserting this equation into \cref{quasisteadymichaelis}, one obtains:
\begin{align}
 c_{ES}(t)=\frac{c_{E_0} c_S(t)}{K_M+c_S(t)}
\end{align}
The combination of this eq. with the differential \cref{first} defines the velocity of the reaction:
\begin{align}
 v(t)= \frac{dc_P(t)}{dt}= k_{\mathrm{c}} \frac{c_{E_0} c_S(t)}{K_M+c_S(t)} = v_{max} \frac{c_S(t)}{K_M+c_S(t)}  
\end{align}
where, $v_{max}=k_c c_{E_0}$ is the maximum velocity. In 1987 the approximation was shown to hold for $c_{E_0}\ll K_M \text{ or } K_M \ll c_{S_0}$ by \citet{Palsson1987}. In 1997 a closed form for the kinetics of the Michaelis-Menten mechanism with the quasi-steady state approximation was derived by  \citet{Schnell1997}:
\begin{align}
 c_S(t)&=K_M \mathrm{W_0}\left[\frac{c_{S_0}}{K_M} \exp \left( \frac{-v_{max} t + c_{S_0}}{K_M}\right)\right],  \label{tiemdependedC_S} \\
 c_{ES}(t)&= \frac{c_{E_0} c_S(t)}{K_M+c_S(t)} \lbrace 1- \exp \left( - \left[ K_M + c_S(t) k_{+} \right] \right) \rbrace, \label{timedendendces}\\ 
 c_{E}(t)&=c_{E_0}(t)-c_{ES}(t), \label{timedendendce}\\
 c_{P}(t)&=c_{S_0}-c_S(t)+c_{ES}(t), \label{timedendendcp}
\end{align}
where,  $\mathrm{W_0(x)}$ is the upper branch of the Lambert W function. The quasi-steady state approximation was applied in the derivation of $c_S(t)$. A time independent   concentration of complexes $c_{ES}$ is conventionally solved for the transitions regime $t \ll t_c$ by approximating $c_S(t \ll t_c) \approx c_{S_0}$. For \cref{timedendendces}, the result for the time independent $c_{ES}$ was extended to the total time period ($0<t<\infty$) by applying time dependent $c_S(t)$ from \cref{tiemdependedC_S}. For normal diffusion, theses equation will be used to model the concentrations obtained from the simulation.  Still, for a small number of particles the deterministic approach may differ from the averages of the stochastic simulation \cite{Turner2004}.\par
The quasi-equilibrium approximation is the second very common approximation, typically applied on setups with high enzyme concentrations. It is assumed that the binding step quickly reaches an equilibrium state ($c_S c_E/c_{ES}=K_S$). $K_S=k_-/k_+$ is the dissociation constant and the rate of product formation can be written as:
\begin{align}
 v={\frac{V_{max} c_S}{K_S+ c_S}}
\end{align}
The assumption was shown to be true for $c_{E_0}\gg K_M \text{ or } k_- \gg k_c$ by \citet{Palsson1987}.\par  An early description of reaction kinetics with fractional diffusion was done by Kopelman \cite{Kopelman1988} for a percolation cluster with a scaling theory and an upgraded time depended reaction rates. This concept was applied by Berry \cite{Berry2002} and Schnell \cite{Schnell2004} for the Michaelis-Menten mechanism.
\section{Simulation Model}
The simulation of the Michaelis-Menten mechanism \cref{eq:michaelismechanism} and fractional Brownian motion with the circulant method by Davis-Harte \cite{Dieker2004} and modified Lowen was setup up with RevReaDDy. Four particle types were defined: substrate, product, complex and enzyme. Again, the reaction radius $\sigma$ will be used as units of length and  $\Gamma$ as units of time, with $\Gamma^{\alpha}=\sigma^2/6 K_{\alpha} $.   Substrates and products were set to diffuse with the same diffusion constant $K_{\alpha}=1 \sigma^2 / \Gamma^{\alpha} $. Enzymes and complexes are modelled to be immobile with $K_{\alpha}= 0 \sigma^2 / \Gamma^{\alpha} $. Enzymes are typically larger than substrates or products and therefore, diffuse therefore slower ($D\approx k_B T/6 \pi \eta a$).  A single enzyme was set in the origin $(x,y)=(0,0)$ and 20 substrates were placed randomly in the simulation box with various box sizes and periodic boundary conditions. The length of the quadratic box $L=8 \sigma$ was set fixed, but could be used as a parameter to control the concentration. Two association/decay reaction types were defined:  \ch{S + E <=>[$ k_+ $][$ k_- $] ES} and \ch{P + E <-[$ k_c $] ES} with intrinsic reaction rates $\lambda_+$,$\lambda_-$ and $\lambda_c$ for complex formation, decay into substrate and enzyme and decay into product and enzyme, respectively. The reaction radius $\sigma$ was set equal for both reaction types to be $1 [\sigma]$. A desired simulation length of $M=2^{14}$ steps and length of the time step $\Delta t=0.05 \sigma^{2/\alpha}/6 K_{\alpha}^{\alpha} \Gamma $ was set. In this simulation setup and regardless of $\alpha$ the particles on average travel for $n=20$ steps $\sqrt{6K_{\alpha} n \Delta t^{\alpha}} \sigma$ to overcome the distance $\sigma$. Further the reaction probability  as approximated in \cref{propabilityreaction} should be a lot smaller than  $P(\Delta t)=\lambda \Delta t \ll 1$. Otherwise that approximations fails to describe the correct reaction probability $P(t)=1-\exp(-\lambda t)$. This is a short-coming of the implementation. Simulations for various $\lambda_+$ ,$\lambda_-$,$\lambda_c$, box size $L$ and $\alpha$ were performed. The results are discussed in the next two sections. 
\section{Results for Normal Diffusion}
First, simulations with normal diffusion were set up to verify our simulation model  with the results from Smoluchowski \cite{vonSmoluchowski1906} and Erban-Chapman \cite{Erban2009} and classical Michaelis-Menten mechanism. The difference in kinetics of the Michaelis-Menten mechanism to the Erban-Chapman problem is a possible blocking of enzymes. Thus, slowing down the reaction speed. Also, a higher local concentration of the substrates in close proximity to the enzyme  is present because of the back reaction. At first a reaction similar to the Erban-Chapman problem was aimed to simulate. Therefore,  $\lambda_-=0 $  was chosen to avoid the effect of a higher local concentration of substrates and $\lambda_+ < \lambda_c$ to reduce enzyme blocking. Thereafter, the normal MM mechanism was studied. 
\subsection{One-Way Reactions}
\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{./data/chapman-limit-concentrations1.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{Scenario: One-way "Erban-Chapman" reaction. Normalised concentrations of substrate, product and complexes are displayed as solid lines. \cref{tiemdependedC_S}(QSSA) was fitted to $c_s(t)$. The resulting $k_+=0.36\sigma^3/\Gamma$ from the fit was inserted in \cref{timedendendces,timedendendcp} and plotted as empty circles. The blue bar in the plot indicates the area where the radial distribution was sampled (see \cref{fig:diffusion_limit-Erban-Chapmann_radial}). Parameters were set to:  $\lambda_+=0.1 /\Gamma$, $\lambda_-=0$,  $\lambda_c=1.0 /\Gamma $.}
  \label{fig:diffusion_limit-Erban-Chapmann}
\end{figure}
\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{./data/chapman-limit-radial_alpha_better.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{ The radial distribution function \ref{eq:messsungradial} of the substrates around the enzyme/complex was sampled in the range of ($100 \Delta t<t<2^{14}\Delta t$) and plotted as error-bars with the width of the standard deviation. The Erban-Chapman \ref{erbanchapmanradial1} result was plotted as a solid black line.\\ green: One-way "Erban-Chapman" reaction:  $\lambda_+=0.1/\Gamma$, $\lambda_-=0$,  $\lambda_c=1.0/\Gamma$.\\blue: One-way "diffusion-limited" reaction: $\lambda_+=3.0/\Gamma$, $\lambda_-=0$,  $\lambda_c=3.0/\Gamma$  }
  \label{fig:diffusion_limit-Erban-Chapmann_radial}
\end{figure}

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{./data/chapman-limit-concentrations1_k1.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{Two scenarios, with three different calculations of $k_+$ are displayed:}
  \begin{small}
  \begin{itemize}
  \item green: One-way "Erban-Chapman" reaction :  $\lambda_+=0.1/\Gamma$, $\lambda_-=0$,  $\lambda_c=1.0/\Gamma$.
  \item blue: One-way "diffusion-limited" reaction: $\lambda_+=3.0/\Gamma$, $\lambda_-=0$,  $\lambda_c=3.0/\Gamma$.
  \end{itemize}
  \begin{enumerate}
  \item $k^{QSSA}_+$ was calculated from the fit of the substrate concentration \cref{tiemdependedC_S} with the QSSA and displayed as a solid line
  \item $k^{count}_+$ was calculated from the number of reactions with \cref{reactioncount} displayed as empty circles.
  \item  $k^{EC}_+$ was obtained form the Erban-Chapman \cref{kalphaerbanchepmann} and plotted as a dotted line.
  \end{enumerate}
  \end{small}

 \begin{comment}
  
 
  \\ green: One-way reaction:  $\lambda_+=0.1$, $\lambda_-=0$,  $\lambda_c=1.0$.\\blue: One-way "diffusion-limited" reaction: $\lambda_+=3.0$, $\lambda_-=0$,  $\lambda_c=3.0$.\\ A comparison of $k_+$ from three different calculations:\\ 1. $k_+$ was calculated from the fit of the substrate concentration \cref{tiemdependedC_S} with the QSSA and displayed as a solid line \\ 2.  $k_+$ was calculated from the number of reactions with \cref{reactioncount} displayed as empty circles.\\ 3. $k_+$ was obtained  form the Erban-Chapman \cref{kalphaerbanchepmann} and plotted as a dotted line. \\ }
   \end{comment}

  \label{fig:diffusion_limit-Erban-Chapmann_k1}
\end{figure}
The first simulation was performed under normal diffusion $\alpha=1$ and with $\lambda_-=0 $, $\lambda_+=0.1 /\Gamma$, $\lambda_c=1.0 /\Gamma$ and in a simulation volume of $L^3=(8 \sigma)^3$. The initial concentrations are $c_{S_0}=5/128\sigma^3$ and $c_{E_0}=1/512 \sigma^3$. The reaction mechanism results in:
\begin{align} \label{eq:michaelismechanismneu}
\ch{S + E ->[$ k_+ $] ES -> [ $k_c $]P + E}
\end{align}
$\lambda_+$ was set to be the rate limiting step in the reaction chain and $\lambda_c$ was set to reproduce approximately the Erban-Chapman problem.
The normalised number of substrates $c_{S}(t)/c_{S_0}$, the normalised number of products $c_{P}(t)/c_{S_0}$ and the number of complexes $c_{ES}(t)$ was sampled over $2544$ runs. The averages are visualised in a double logarithmic plot in \cref{fig:diffusion_limit-Erban-Chapmann}. Every run started with a new uniformly-distributed initial position of the substrate molecules in the simulation volume. The concentration of enzymes is 20 times smaller than the concentration of substrates. Equations (\ref{tiemdependedC_S} - \ref{timedendendcp})  were chosen to model the concentrations resulting from the simulation. The microscopic reaction rates and macroscopic reaction rate for a uni-molecular reaction should be equal $\lambda_c=k_c$. In \cref{tiemdependedC_S} $k_+$ was fitted to the sampled concentration. A blue bar in the plot indicates the time window during which the radial distribution was sampled. The corresponding radial distribution will be discussed here after. It was assumed that after $t=100 \Delta t$ steps a stationary distribution was reached. The assumption is based on an approximated constant average number of complexes from there on. The simulation is reproducing the theoretical kinetics. The simulation is not yet reaching equilibrium, with $c_S=0$ and $c_P=c_{S_0}$, at the end of the simulation. The theoretical values however are calculated two decades further. \par
The next observable of interest is the radial distribution function ($g_{S,E}(\bm{r})$) of substrates around enzymes. It describes how the conditional density varies as a function of distance ($\bm{r}$) between enzyme and substrate particles:  
\begin{align}
 g_{S,E}(|\bm{r}|;t)=\frac{1}{ N_S (t) N_E(t)} V \sum_{ij} \langle \delta(\bm{R}_{S i}(t)-\bm{R}_{E j}(t)-\bm{r})\rangle
\end{align}
 $\bm{R}_{S j}(t)$ denotes the position of molecule $i$ of species $S$ at time t and $i=1,...,N_{S}$.
In a simulation the radial distribution function can be calculated form the number of substrates $dn(r)$ within an interval $r,r+dr$ away from the enzyme:
\begin{align} 
 g_{S,E}(r;t)=\frac{V dn(r)}{  N_S (t) N_E(t) 4\pi r^2 dr} \label{eq:messsungradial}
\end{align}
In a simulation box with periodic boundary conditions, one cannot obtain the structure beyond $r>L/2$. Thus, $g_{S,E}(r;t)$ was sampled in the range $0 <r<4.0 \sigma$ and averaged over the time window ($t=100 \Delta t ...819 \Delta t$). An ensemble-average of 2544 runs was performed on top. The time-ensemble-average was plotted as green error bars in \cref{fig:diffusion_limit-Erban-Chapmann_radial} and compared to Erban-Chapman \cref{erbanchapmanradial1,erbanchapmanradial}. Again, the simulation is reproducing with good accuracy the radial distribution obtained by \cref{eq:messsungradial}. The radial distribution is deviating from Erban-Chapman only for $r$ close to the enzyme and close to the simulation box boundary. $dr$ was chosen constant. Hence, the volume of the shell decreases for small $r$, which makes the calculation less accurate for $r\rightarrow 0$. That is also the reason for the standard deviation, which is displayed as the error-bars, to increase for $r\rightarrow 0$.  Erban-Chapman equations are derived by a constant concentration of substrates at infinity. This explains the deviation of the simulation to Erban-Chapmen result close to the boundary of the simulation box. For a better agreement, substrates should be inserted at the boundaries during the simulation to obtain a stationary concentration. 
\par 
The forward macroscopic reaction rate $k_+$ was shown by Erban-Chapman to be constant in time for our scenario. In the following $k_+$ will be obtained by three different ways:
\begin{enumerate}
 \item From a fit of $k^{QSSA}_+$ in any eq. (\ref{tiemdependedC_S} - \ref{timedendendcp}) to the simulated data.
 \item $k^{EC}_+$ from the Erban-Chapman theory with \cref{kalphaerbanchepmann}.
 \item From the number of forward reactions $dN_{react}$ of the reaction \ch{S + E ->[$ k_+ $] ES} within $\tau$.  
 \begin{align} \label{reactioncount}
  k^{count}_+(t)=\frac{ \langle dN_{react}\rangle}{dt}\frac{1}{V c_S(t) c_E(t)}= \frac{1}{V c_S(t) c_E(t)} \lim_{\tau \to 0} \frac{dN_{react}}{\tau}
 \end{align}
\end{enumerate}
$V$ is the volume of the simulation box. $k_+$ was very noisy. A reasonable smooth $k_+(t)$ could be obtained for $\tau=300 \Delta t$. Only the third method calculates the macroscopic forward reaction rate at different times. For the first and second method, $k_{+}$ is assumed constant in time. This assumption holds for Brownian motion but not for fractional Brownian motion. The forward reaction rates have been calculated with the three methods and plotted  as the green in \cref{fig:diffusion_limit-Erban-Chapmann_k1}. The reaction rate from method 1 and 3 are accurate. They both reproduce similar forward reaction rates. $k^{QSSA}_{+}=0.359 \sigma^3/\Gamma$ is inside the standard deviation of the mean of  $k^{count}_+=(0.360\pm0.003)\sigma^3/\Gamma$ from the counted reaction number. The second method rely on a constant concentration of substrates at the boundary. This might cause this method to underestimate the reaction rate $k^{EC}_{+}=0.338 \sigma^3/\Gamma$. The second method rely solely on the theory and not on the simulation data. The simulation model reproduces the kinetics and spatial distribution of the theoretical results of Erban-Chapman.
\subsubsection{"Diffusion-Limited" One-Way Reaction}
\begin{figure} [h]
  \centering
  \includegraphics[width=\textwidth]{./data/diffusion-limit-concentractionlambdaminus_k1}
  \captionsetup{width=\linewidth}
  \captionof{figure}{Displayed is the saturation of macroscopic reaction rates with an increase of $\lambda_+$ towards a "diffusion-limited" reaction. $k^{QSSA}_{+}$ was calculated and displayed as empty circles. The dashed blue line describes the diffusion limit \cref{difkinetics}.  Microscopic rates  were varied in the range of:  $1 /\Gamma\leq\lambda_+\leq3.0/\Gamma$. The remaining  microscopic rates were chosen: $\lambda_c=1.0/\Gamma$, $\lambda_-=0$.}
  \label{fig:diffusionlimit_k1}
\end{figure}
\begin{comment}
\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{./data/chapman-limit-radial_alpha_better.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{The radial distribution function of the substrates around the enzyme / complex was observed for $5<t<900$ and plotted as a blue line with an error-bar of the standard deviation. The Erban-Chapman result was plotted as a green dashed line for bigger than the reaction radius $\sigma$  and a red dashed line for smaller than $\sigma$. Parameters were set to:  $\lambda_+=3.0$, $\lambda_-=0$,  $\lambda_c=3.0$ and the box size $l^3=8^3$.}
  \label{fig:diffusion1_limit-radial}
\end{figure}
\end{comment}
A scenario with reaction speed being limited by diffusion was tried to simulated. Therefore, diffusion has to be the rate limiting step. However, the microscopic rates cannot be chosen arbitrarily high, due to \cref{propabilityreaction}. The Microscopic rates $\lambda_+=3.0$ and $\lambda_c=3.0$ were chosen so that the reaction probability $P=0.15$  for one step is still a lot smaller than 1. Again the box size $L^3=8^3$ was fixed. The resulting radial distribution is shown as blue error bars in \cref{fig:diffusion_limit-Erban-Chapmann_radial} and compared to the Erban-Chapmann result \ref{erbanchapmanradial1}, displayed as a blue solid line. The result, is reproducing the theory very accurately. Also the macroscopic reaction rate forward was calculated analogously to description of the previous scenario and displayed in blue in \cref{fig:diffusion_limit-Erban-Chapmann_k1}. Erban-Chapmans results are underestimating  $k_+$ even more than in the last scenario. The impact of non-stationary concentrations at the boundaries is probaly even stronger for "diffusion-limited" reactions. Even for the closest scenario to reactions being limited by diffusion, the quasi steady state approximation still should hold because of $ c_{E_0}\ll K_M$  as stated by \cite{Palsson1987}. $k^{QSSA}_{+}=2.22 \sigma^3/\Gamma$ is inside the standard deviation of the mean of $k^{count}_{+}=(2.25\pm0.08)\sigma^3/\Gamma$ from the counted reaction number.\par
Subsequently,  $1\leq\lambda_+\leq3.0$ was scanned until diffusion becomes the rate limiting step. $k^{QSSA}_{+}$ was calculated for every simulation. The fastest possible reaction should be limited by \cref{difkinetics} to be $k_+=2.094 \sigma^3/\Gamma$.The change of $k^{QSSA}_{+}$ with $\lambda_+$ is displayed in \cref{fig:diffusionlimit_k1}. Higher reaction rates than the diffusion limit  result for $\lambda_+>2.0 /\Gamma$ possibly because no extra particles were placed at the boundaries to indeed have a quasi stationary distribution. 
\begin{comment}
  

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{./data/diffusion-limit-concentractionlambdaminus_k1.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{ Parameters were set to:  $\lambda_c=1.0$,  and the box size $l^3=8^3$. The green solid line shows macroscopic rates $k_+$ in respect to  microscopic rate $1\leq\lambda_+\leq3.0$ for $\lambda_-=0$ and the blue solid line for $\lambda_-=1$. The macroscopic rates are obtained with a fit of the substrate concentration \cref{tiemdependedC_S} with the QSSA. The diffusion limit \cref{difkinetics} is plotted as the dashed blue line.}
  \label{fig:diffusionlimit_k1variouslambda}
\end{figure}
 \end{comment}
 \newpage
\subsection{Michaelis-Menten mechanism}
\begin{figure} [h]
  \centering
  \includegraphics[width=\textwidth]{./data/highlocaldensityconcentrationversion2.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{Scenario: "enzyme blocking" Michaelis-Menten. Normalised concentrations of substrate, product and complex and their fit with the quasi-steady state approximation for the substrate concentration are shown. The blue bar in the plot indicates the area where the radial distribution was observed, which is plotted in \cref{fig:diffusion_limit-Erban-Chapmann_radial}. The remaining Parameters were set to:  $\lambda_+=1$, $\lambda_-=1$,  $\lambda_c=0.1$}
  \label{fig:enzyme_blocking}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{./data/limit-radial-highlocalconcentration.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{Scenario: "enzyme blocking" Michaelis-Menten. For $\lambda_+=1.0/\Gamma$, $\lambda_-=1.0/\Gamma$,  $\lambda_c=0.1/\Gamma$, the radial distribution function \ref{eq:messsungradial} of the substrates around the enzyme/complex was sampled in the range of ($100 \Delta t<t<2^{14}\Delta t$) and plotted as error-bars with the width of the standard deviation. The Erban-Chapman \ref{erbanchapmanradial1} result was plotted as a solid black line.}
  \label{fig:diffusion1_limit-radial_local concentration}
\end{figure}
The MM mechanism was simulated for $\lambda_{-}=1.0/\Gamma >\lambda_c=0.1/\Gamma$ and $\lambda_{+}=1.0/\Gamma>\lambda_c=0.1/\Gamma$ to have a locally higher concentration of substrates around the enzyme. The kinetics were calculated with the same method as described in the previous section. The concentrations of substrate, enzyme and product are displayed in \cref{fig:enzyme_blocking} in solid lines. The kinetics of the one-way reaction with same parameters but $\lambda_{-}=0.0/\Gamma $ are displayed as a transparent line. One can see that indeed the blocking is decreasing the reaction velocity $dc_p/dt$.Again,  equations (\ref{tiemdependedC_S} - \ref{timedendendcp})  were chosen to model the concentrations resulting from the simulation. They reproduce the simulation accurately. One can see the concentration of complexes to be higher as intended for the Michaelis-Menten scenario. $k^{QSSA}_{+}=4.34 \sigma^3/\Gamma$, from the fit of \cref{tiemdependedC_S}, results in a higher reaction rate than the Erban-Chapman result $k^{EC}_{+}=1.25 \sigma^3/\Gamma$. Also the method of counting reactions \cref{reactioncount} yields a comparable macroscopic reaction rate $k^{count}_{+}=(4.39\pm0.02) \sigma^3/\Gamma$. The reason for $k^{EC}_{+}$ to be smaller is presumably a high local concentration of substrates around the enzyme. The radial distribution function was plotted in \cref{fig:diffusion1_limit-radial_local concentration} with the Erban-Chapman result as a reference. As expected, the radial distribution shows a lot higher concentrations of substrates in close proximity.
\begin{comment}
 


\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{./data/normal-scenario-concentrations.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{ Normalized concentrations of substrate, product and complex and their fit with the quasi-steady state approximation for the substrate concentration are shown in the loglog plot. The blue bar in the plot indicates the area where the radial distribution was observed, which is plotted in \cref{fig:diffusion_limit-Erban-Chapmann_radial}. Parameters were set to:  $\lambda_+=1$, $\lambda_-=1$,  $\lambda_c=1.0$ and the box size $l^3=8^3$.}
  \label{fig:normalscenario_reaction}
\end{figure}
averaged over 8700 runs
\end{comment}
\newpage
\begin{comment}
\newpage
\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{./data/erban-chapman-limit-concentrations1.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{ Erban Chapmann Concentrations}
  \label{fig:diffusion_limit-Erban-Chapmann}
\end{figure}
\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{./data/chapman-limit-concentrations1_k1.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{ Erban Chapmann $k1$}
  \label{fig:diffusion_limit-Erban-Chapmann_k1}
\end{figure}
\end{comment}
\begin{comment}
\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{./data/microrate_complex_radial_erban.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{ Radial distribution for differnt $k_{c}$ }
  \label{fig:microrate_complex_radial_erban}
\end{figure}
\newpage

\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{./data/microrate_complex_vsmicrorate_forward_radial_erban.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{ Radial distribution for $\lambda_{-}=0$ }
  \label{fig:microrate_complex_vsmicrorate_forward_radial_erban}
\end{figure}
\newpage

\newpage
\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{./data/differentalphamsdrevreaddy.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{ different alpha}
  \label{fig:differentalpharevreaddymsd}
\end{figure}
\end{comment}
\section{Results for fBm}
The mass action law does not hold any more for reactions with fractional Brownian motion. Kopelman suggested for percolation cluster, in which particles diffuse  anomalously, to have time depended macroscopic reaction rates for bi-molecular reactions of the form \cite{Kopelman1988}:
\begin{align} \label{ktime}
k(t)=k_0 t^{-h} \qquad \text{for} \qquad 0 \leq h \leq 1 \qquad \text{and} \qquad t \geq 1,
\end{align}
with $h$ the fractal kinetics exponent. Its value is zero for classic kinetics.  For  diffusion limited kinetics in a percolation cluster and a bi-molecular reaction \ch{A + A}, Kopelman derived a relation between fractal like kinetics exponent $h$ and the spectral density $d_s$:
\begin{align}
 h=1-\frac{d_s}{2}
\end{align}
The spectral dimension is defined by the recurrence probability $\mathrm{P}$ of a random walker to return to its origin after time t:
\begin{align}
 P\sim t^{-d_s/2}
\end{align}
The spectral dimension can be related to the anomalous coefficient $d_s=d \alpha$. 
The fractal exponent $h$ as a result of percolation theory can be related to $\alpha$ for a three-dimensional, diffusion-limited reaction \ch{A + A} as:
\begin{align} \label{koppelmaneq}
 h=1-\frac{3 \alpha}{2} \qquad \text{for} \qquad 0<\alpha<2/3 \\
 h=0 \qquad \text{for} \qquad 2/3<\alpha<1
\end{align}
In the kinetics of fractional Brownian motion with $\alpha=0.5$ have been compared to the same system with normal diffusion $\alpha=1$. Subsequently, the impact of $\alpha$ on $k_{+}$ for one scenario was studied and compared to the theory for percolation cluster mentioned above. The initial densities of substrates $c_{S_0}=5/128\sigma^3$ and enzymes  $c_{E_0}=1/512 \sigma^3$ and diffusion coefficient $K_{\alpha}$ remained unchanged.
\subsection{Comparison to Normal Diffusion}
\begin{figure} [h]
  \centering
  \includegraphics[width=\textwidth]{./data/highlocaldensityconcentrationversionfbmvsbm.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{Scenario: fBm influenced Michaelis-Menten reaction. Normalised concentrations of substrate, product and complex and their fit with the quasi-steady state approximation for the substrate concentration are shown. The blue bar in the plot indicates the area where the radial distribution was sampled, which is plotted in \cref{fig:diffusion_limit-Erban-Chapmann_radialfbmfast}. The remaining Parameters were set to:  $\lambda_+=1.0$, $\lambda_-=1.0$,  $\lambda_c=1.0$. }
  \label{fig:enzyme_blocking_fbm}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{./data/chapman-limit-radial_alpha_betterfbm.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{The radial distribution function \ref{eq:messsungradial} of the substrates around the enzyme/complex was sampled in the range of ($100 \Delta t<t<2^{14}\Delta t$) and plotted as error-bar with the width of the standard deviation and microscopic reaction set to: $\lambda_+=1.0/\Gamma$, $\lambda_-=1.0$,  $\lambda_c=1.0/\Gamma$.\\ green: Michaelis-Menten reaction: $\alpha=1.0$
  \\blue: "fBm-influenced" Michaelis-Menten reaction: $\alpha=0.5$ }
  \label{fig:diffusion_limit-Erban-Chapmann_radialfbm}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{./data/chapman-limit-radial_alpha_betterfbmfast.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{Scenario: An attempt of fast fBm reactions. The radial distribution function \ref{eq:messsungradial} of the substrates around the enzyme/complex was sampled in the range of ($100 \Delta t<t<2^{14}\Delta t$) and plotted as error-bar with the width of the standard deviation and microscopic reaction set to: $\lambda_+=1.0/\Gamma$, $\lambda_-=1.0$,  $\lambda_c=0.02/\Gamma$.\\ green: Michaelis-Menten with Bm: $\alpha=1.0$
  \\blue: Michaelis-Menten with fBm: $\alpha=0.5$ }
  \label{fig:diffusion_limit-Erban-Chapmann_radialfbmfast}
\end{figure}

For the first simulation, $\lambda_+=1.0/\Gamma$, $\lambda_-=1.0$,  $\lambda_c=1.0/\Gamma$ 
an diffusion influenced scenario was chosen. The kinetics are shown in solid line in \cref{fig:enzyme_blocking_fbm}. In transparent the same scenario with normal diffusion is plotted. A slowing down of the kinetics compared to normal diffusion is obvious. The concentration of complexes is not constant in time during the time window indicate as a blue bar in the figure. Thus, a QSSA ($dc_C/dt=0$) should not hold. Still the radial distribution function was sampled in the time window indicated by the blue bar and compared to normal diffusion. The radial distribution function is displayed in \cref{fig:diffusion_limit-Erban-Chapmann_radialfbm}. One can see a stronger depletion of substrates close to the enzyme than for normal diffusion. \par
A second scenario with $\lambda_+=1.0/\Gamma$, $\lambda_-=1.0$,  $\lambda_c=0.02/\Gamma$  and $\alpha=0.5$ was set up. Intended was a scenario, where kinetics are accelerated due to fBm. With $\lambda_c \gg\lambda_-$, the idea was to increase the density of substrates locally around the enzyme. substrates which propagated with fBm should have more difficulties to escape out of the reaction radius. With similar microscopic reaction rates a higher density of substrates would cause a higher reaction rate. The radial distribution function of an attempt of fast kinetics with fBm are shown in \cref{fig:diffusion_limit-Erban-Chapmann_radialfbmfast}. The local concentration of substrates around the enzyme is higher for normal diffusion. The impact of slower escape probability is presumably overcompensated by an lower arrival probability of the substrates.

\subsection{Fractal Kinetics}
\begin{figure}[h]
  \centering
  \includegraphics[width=\textwidth]{./data/fractionalalphachangek1neu.png}
  \captionsetup{width=\linewidth}
  \captionof{figure}{Scenario: "fBm-influenced" Michaelis-Menten reaction. For  $\lambda_+=1.0$, $\lambda_-=1.0$,  $\lambda_c=1.0$, the impact of $\alpha$ on $k^{count}_+(t)$ is displayed as empty circles in the range of $0.05\leq\alpha\leq1.0$. With \cref{ktime} the fractal like kinetics exponent $h$ was fitted and displayed as dashed lines in the plot.  }
  \label{fig:k1differentalphawithfitbetter}
\end{figure}
\begin{figure}[h]
  \centering
  \includegraphics[width=0.45\textwidth]{./data/hvsalpha.png}
  \qquad
  \begin{tabular}[b]{ l | c | r }
  $\alpha$ & $h^{fit}(\alpha)$ & $h^{theo}(\alpha)$ \\
  \hline
  0.05 & 0.88441 & 0.925 \\
  0.1 & 0.80584 & 0.85 \\
  0.2 & 0.65659 & 0.7 \\
  0.3 & 0.46603 &  0.55  \\
  0.4 & 0.33364 & 0.4 \\
  0.5 & 0.18971 & 0.25 \\
  0.6 & 0.10969 & 0.1 \\
  0.7 & 0.03544 & 0.0 \\
  0.8 & 0.01657 & 0.0 \\
  0.9 & 0.01320 & 0.0 \\
  1.0 & 0.0 & 0.0\vspace{1.0cm}
  \end{tabular}
  \captionlistentry[table]{Impact of $\alpha$ on $h$ resulting from a fit ($h^{fit}$) of the simulations displayed in \cref{fig:k1differentalphawithfitbetter} and from the percolation theory ($h^{theo}$). }
  \captionsetup{labelformat=andtable}
  \captionof{figure}{Impact of $\alpha$ on $h$ resulting from a fit ($h^{fit}$ of the simulations displayed in \cref{fig:k1differentalphawithfitbetter} and from the percolation theory $h^{theo}$.}
  \label{fig:k1differentalphawithfitbetter1}
\end{figure}
As suggested by the theory for a "diffusion limited" $A+A$ reaction in a percolation cluster the rate coefficients should become time depended for $\alpha>2/3$ as described by \cref{koppelmaneq}. The impact of $\alpha$ on $k^{count}_+(t)$ was simulated for a "fBm-influenced" Michaelis-Menten reaction with microscopic reaction rates  $\lambda_+=1.0$, $\lambda_-=1.0$,  $\lambda_c=1.0$.  $k^{count}_+(t)$ for $0.05>\alpha>1$ was averaged over at least $2400$ runs and displayed in \cref{fig:k1differentalphawithfitbetter}. The fractional kinetics exponent $h^{fit}$ was fitted via \cref{ktime} and plotted as solid lines into the simulation data. $h^{fit}$ and  $h^{theo}$ from the theory have been compared in \cref{fig:k1differentalphawithfitbetter1}. Theory, although formulated for percolation cluster, and simulation are in good agreement.
\section{Conclusion}
The simulation model is capable of reproducing the theoretical results of Smoluchwoski and Erban-Chapman for a bi-molecular reaction One-Way reaction \ch{S + E ->[$ k_+ $] ES -> [ $k_c $]P + E}. Reactions influenced most by diffusion showed the strongest deviations from theory. However, in theory a constant concentration of substrates is assumed at $r\rightarrow \infty$, which is not the case in the simulation. The simulation model can also be described by Michaelis-Menten kinetics with the QSSA for $c_S(t)$ and normal diffusion. $c_{S_0}/c_{E_0}=20$ was chosen to be sufficient for the QSSA to hold. From theory, QSSA holds for $c_{S_0}\gg c_{E_0}$. The Michaelis-Menten mechanism results in locally higher concentration of substrates around the enzyme in comparison to one-Way reactions. The previous simulations, with theory as reference, deal as a validation of the simulation model. This modelled was  used to simulate a Michaelis-Menten mechanism with fractional Brownian motion in a diffusion influenced regime. No scenario with enhanced kinetics to fBm was found, but all simulations in a diffusion controlled regime were of fractal type. The impact  of slower escape probability on kinetics is presumably overcompensated by an lower arrival probability of the substrates.  A stronger depletion of substrates around enzymes for fBm in comparison to Bm was observed. From percolation theory of a "diffusion-controlled" bi-molecular reaction, the fractal kinetics exponent, was compared with good agreement to results generated by the simulation in the range of $0.05<\alpha<1.0$. Theses results indicate the simulation model also to work with particles propagating by fBm. 

\begin{comment}
 

The modeling of biological reaction-diffusion dynamics with fBm can be interesting in a large system with a high number of particles not involved in the reaction mechanism but a small number of reactants, which diffuse anomalously. The large number of particles not  have to be simulated explicitly. There influence on diffusion of the reactants is incorporated in fBm. The missing particle-particle interactions might get negligible with a low density of particles.  
\end{comment}

\chapter{Summary}
In cells, reaction-diffusion simulations are particularly challenging. On one hand, large numbers of macromolecules densely packed causes classical particle-based simulations to reach computational limits very early.  On the other hand, small molecular abundances of particular species cause simulations based on a "well-mixed assumption" to be inaccurate, although computationally favourable. For a specific reaction-diffusion system, only specific reactions are of interest. Most of the molecules, thereby, are not involved in reactions but induce anomalous diffusion. The aim of this thesis is to tackle the impact of anomalous diffusion on reaction-diffusion systems. \par
Diffusion was chosen to be modelled by fractional Brownian motion. This approach approximates the influence of the crowded medium by long-range correlations of the trajectory increments. First, theoretical foundations for fBm were set. Most importantly auto-covariance functions for fractional Brownian noise and motion were introduced. Subsequently, fBm-generating algorithms were studied in terms of accuracy and performance. They rely on Wiener-Khintchin's theorem and the auto-covariance functions introduced beforehand .A naive, Cholesky, Davis-Harte and Lowen fBm-generating algorithms were implemented and analysed in terms of accuracy and performance. Our implementation of Lowen's algorithm turned out not to be exact as claimed by the author\cite{Lowen1999}. A slightly modified version of Lowen's algorithm was introduced. The modified version turned out to overcome the problem of a non-Gaussian distribution. Davis-Harte and modified Lowen algorithms seam to be both, exact and fast $\mathcal{O}(M log(M))$ with the trajectory length ($M$).\par
Theoretical foundations for bi-molecular reactions were introduced in the second chapter.   Theses elaborations motivate the underlying particle based simulation model for bi-molecular reactions in RevReaDDy. However, the theory is not applicable for fBm. No prognoses, 





The algorithms analysis suggest Davis-Harte and Lowen algorithm to be well suited for an implementation in RevReaDDy. Both algorithms generate all increments beforehand, it caused the major modification to RevReaDDy. In the process of implementation further modifications to RevReaDDy were necessary to address. 


Besides the implementation of fBm many modifications to RevReaDDy were done to deal with our set of questions. A new reaction type and new observables were implemented. Some old observables were modified. A simulation setting with one enzyme and 20 randomly distributed substrates for the Michaelis-Menten mechanism was set up and studied under normal Brownian motion and under fractional Brownian motion. Theoretical results from the Smoluchwoski problem of a diffusion controlled bi-molecular reaction and theoretical results for a bi-molecular reaction with microscopic reactions within close proximity to the enzyme could be reproduced by the simulation. It could be shown that the quasi steady-state assumption is indeed reproducing the kinetics of the Michaelis-Menten mechanism for our setting, although this approach is not considering a non uniform spatial distribution.\par For fractional Brownian motion with $\alpha<1$ and  $t<1$ a general slowing down of reactions compared to normal diffusion was shown. Reaction rates are time depended for MM with fBm if reaction speed is controlled by diffusion, as Kopelman suggested for particles performing reactions in a percolation cluster ($k(t)=k_0 t^{-h}$). The kinetics are of fractal type.  \par
As an outlook of the thesis a mathematical model for fractal Brownian motion and Michaelis-Menten mechanism for 3D could be developed. FBm with forces could be studied. Although a algorithm with possible potentials included will probably be very slow. \begin{comment}
outlook:
''''''''''''''''''''''''''''''''''''''''''''
0.find analytical solution to RDPB with brownian motion (chemical lagevin equation?)
besides smoluchswskis PDE, concentration based models.
%http://scitation.aip.org/docserver/fulltext/aip/journal/jcp/113/1/1.481811.pdf?expires=1481129009&id=id&accname=2120797&checksum=758284E4BA8FBF60E006DFB8857194A9

1.find analytical solution to fractional description. (fractional PDE, fraction ODE, fractional master equation,fractional RDME, fractional chemical lagevin equation,  
 fractional master equation fractional diffusion equation %http://www.hrpub.org/download/201308/ms.2013.010208.pdfhttp://www.hrpub.org/download/201308/ms.2013.010208.pdf)
 Fractional master equation and fractal time random walks
 %https://www.icp.uni-stuttgart.de/~hilfer/publikationen/pdfo/PRE-1995-51-R848.pdf
 
2.introduce forces (complicated)

2.1 find analytical solution

3. find similar time depended reaction rates with interaction potentials, obstacles and Brownian dynamics (interesting for presentation, first this simulation with mean square displacement. then let all the other particles vanish and fbm is performed. on the side msd is shown simultaneous how it develops.problem no excluded volume but not so important cause, small abundances are especially interesting.)
''''''''''''''''''''''''

Outlook in two section
1: scientifically interesting :
-introduce forces (complicated) and find find analytical solution
-find analytical solution to RDPB with brownian motion (chemical lagevin equation?) besides smoluchswskis PDE, concentration based models.
- Fractional master equation and fractal time random walks


2:interesting for integration as an modeling tool:
-not only fBm but any velocity correlation function measured by n experiment
-introduce forces (complicated)
-verify by finding similar time depended reaction rates with interaction potentials, obstacles and Brownian dynamics 
\end{comment}
 
 
\chapter{Appendix}
\section{From Central Limit Theorem to Gaussian Distribution}\label{append:CLT}
In the following the Central Limit Theorem will be applied to calculated the distribution of Y,  $\rho(y)dy=P(y<Y<y+dy)$ in the limit of large N , with Y being defined as the sum of an random variable:
 \begin{align}
  Y = \frac{1}{\sqrt{N}} \sum_{j=1}^N X_j \label{eq:CLT1}
 \end{align}
The Generating function for a random variable $Y$ is: 
\begin{align}
 G_Y(k)=\langle e^{ikY}\rangle = \int e^{ikY} \rho(y)dy
\end{align}
\cref{eq:CLT1} can be inserted into the generating function, which results in:
\begin{align*}
G_Y(k)=\langle e^{\frac{ik}{\sqrt{N}} \sum_{j=1}^N X_j}\rangle \\
G_Y(k)=\langle \prod_{j=i}^N e^{\frac{ik}{\sqrt{N}} X_j} \rangle 
\end{align*}
If all $X_j$ are independent, then:
\begin{align}
 G_Y(k)= \prod_{j=i}^N \langle e^{\frac{ik}{\sqrt{N}} X_j} \rangle =e^{\sum_{j=1}^N A_j (\frac{k}{\sqrt{N}})} \\ \nonumber \text{ with } A_j(\frac{k}{\sqrt{N}})= ln \langle e^{\frac{ik}{\sqrt{N}} X_j} \rangle 
\end{align}
For large N behavior, we assume $\frac{k}{\sqrt{N}} << 1$ and expand
\begin{align}
 A_j(\frac{k}{\sqrt{N}}) = ln(1+ \langle X_j \rangle \frac{ik}{\sqrt{N}} - \langle X_{j}^2 \rangle \frac{k^2}{2N}+\mathcal{O}(N^{- \frac{3}{2}}))
\end{align}
 with a finite variance $ \sigma_i^2=\langle X_{i}^2\rangle $ and the mean $\langle X_{i}\rangle = 0$
\begin{align}
 A_j(\frac{k}{\sqrt{N}}) = -\sigma_j^2 \frac{k^2}{2N}+\mathcal{O}(N^{- \frac{3}{2}}))
\end{align}

Thus, the generating function for large N is:

\begin{align}
 G_Y(k)=e^{- \frac{\sigma^2 k^2}{2}} \\ \nonumber
 \text{ with } \sigma =  \frac{1}{N} \sum_{j=1}^N \sigma_j^2 
\end{align}
The distribution of Y can be calculated via the inverse Fourier Transform:
\begin{align}
 \rho(y) &=\frac{1}{2 \pi} \int_{-\infty}^{\infty} e^{- \frac{\sigma^2 k^2}{2}} e^{i k y} dk \\  
 &=\frac{1}{\sqrt{2 \pi} \sigma } e^{-\frac{y^2}{2 \sigma^2}}
\end{align}
$\rho(y)$ results in a Gaussian distribution.

\section{From Gaussian Distribution to Gaussian Transition Probability}\label{baystheorem}
The conditional distribution function to be in $x$ at time $t$ if visited position $y$ at time $s$   can be written due to Bayes' theorem as a transition probability from $y$ to $x$ in time $t-s$ multiplied with the probability to be in $y$ at time $s$:
\begin{align}
 \rho_{t,s}(x,y)=T_{t-s}(x|y) \rho_s(y)
\end{align}
Further due to particle conservation another relation holds:
\begin{align}
 \rho_{t}(x)= \int \rho_{t,s}(x,y) dy
\end{align}
Having an initial condition $\rho_{s}(x)= \delta(x-y)$:
\begin{align}
 \rho_{t,s}(x|y)&= \int \rho_{t,s}(x,y) dy = \int T_{t-s}(x|y) \rho_s(y) dy\\
 &= \int T_{t-s}(x|y) \delta(x-y) dy 
 = T_{t-s}(x|y)
\end{align}
\section{Einstein Formula} \label{einsteinrealtionappendix}
The derivative of the mean variance of the Gaussian distribution in respect to time is defined as:
\begin{align}
 \frac{d}{dt}  \delta \bm{r}^2(t)&=\frac{d}{dt} \langle \Delta \bm{ R}^2(t)\rangle  =\frac{d}{dt} \int d\bm{r} \bm{r}^2 c(\bm{r},t)=\int d\bm{r} \bm{r}^2 \frac{\partial}{\partial t} c(\bm{r},t) 
\end{align}
Fick's second law can be applied:
\begin{align}
&= D \int_{-\infty}^{\infty}d\bm{r} \bm{r}^2 \Delta c(\bm{r},t)  
\end{align}
Assuming a reasonable assumption  $c(\pm \infty,t)=0$  and two times partial integration one can derive:
\begin{align}
&= -2 D \int_{-\infty}^{\infty} d\bm{r} \bm{r} \nabla c(\bm{r},t) \\ &= 2 D d \int_{-\infty}^{\infty} d\bm{r} c(\bm{r},t) =2dD
\end{align}
For the initial condition $\bm{r}(0) = 0$,  one gets the Einstein Formula: $\langle (\bm{r}(t)-\bm{r}(0))^2)\rangle= 2dDt$
\begin{comment}
check book zwanzig

\section{Power spectral density for fGn}\label{VACF}
The power spectral density function can be calculated from the Wiener-Khinchin theorem as the Fourier transform the auto-covariance function. The auto-covariance function for ctfGn can be derived from fractional Brownian motion:
\begin{align}
\mathrm{Cov}[X^{\alpha}_t,X^{\alpha}_0]&=\sigma^2 \frac{d^2 |t|^{\alpha}}{dt^2}\\
\end{align}
The power spectral density can be written as the Fourier transform of the auto-covariance function:
\begin{align}
 S(\omega)&= \int^{\infty}_{-\infty} \mathrm{Cov}[X^{\alpha}_t,X^{\alpha}_0] \exp[-2 \pi i \omega t] dt\\
 &=\int^{\infty}_{-\infty} \sigma^2 \frac{d^2 |t|^{\alpha}}{dt^2} \exp[-2 \pi i \omega t]=2 \sigma^2  \int^{\infty}_{0} \frac{d^2 |t|^{\alpha}}{dt^2} \exp[-2 \pi i \omega]
\end{align}
With partial integration one arrives at:
\begin{align*}
  \stackrel{par. integ.}{=}2 \sigma^2 \left( \underbrace{\left [ \exp[-2 \pi i\omega t] \frac{d}{dt} t^{\alpha} \right]_{0}^{\infty}}_{\stackrel{\alpha < 2} {=} 0}+ i \omega \int_{0}^{\infty} d t e^{-2 \pi i \omega t} \left[\frac{d}{dt}t^{\alpha} \right] \right) 
 \end{align*}
Partial integration and Tauber theorem yields:

\begin{align*}
  &\stackrel{par. integ.}{=}2 \sigma^2 \left( \underbrace{\left [ \exp[-2 \pi i\omega t]  t^{\alpha} \right]_{0}^{\infty}}_{\stackrel{\alpha < 1} {=} 0}+ (i \omega)^2 \int_{0}^{\infty} d t e^{-2 \pi i\omega t} \left[ t^{\alpha} \right] \right) \\
  &= \sigma^2 \Gamma(1+\alpha)(i \omega)^{1-\alpha} \qquad \text{for} \qquad \alpha < 1
\end{align*}
\end{comment}

\section{Erban-Chapman}\label{Erban-Chapmann}
The calculation can be started from \cref{smoluchwoskionedimension}. This derivation can be found in \cite{Erban2009}. The stationary distribution can be written as:
\begin{align}
\left(\frac{\partial}{\partial_r}+\frac{2}{r} \right) D \frac{\partial\rho_t(r)}{\partial_r}=0 \qquad \text{for} \qquad r \geq \sigma \\
\left(\frac{\partial}{\partial_r}+\frac{2}{r} \right) D \frac{\partial\rho_t(r)}{\partial_r}=\lambda_{+} \rho_t(r)  \qquad \text{for} \qquad r \leq \sigma
\end{align}
For  $r \leq \sigma$ a production term had been added to the continuity equation. The general solution can be written as: 
\begin{align}
\rho_t(r)= a_1+\frac{a_2}{r} \qquad \text{for} \qquad r \geq \sigma \label{erbanchapmanradial1} \\
\rho_t(r)= \frac{a_3}{r} \exp \left[ r \sqrt{\frac{\lambda_{+}}{D}} \right] + \frac{a_4}{r} \exp \left[-r \sqrt{\frac{\lambda_{+}}{D}} \right] \qquad\text{for}\qquad r \leq \sigma \label{erbanchapmanradial}
\end{align}
with $a_1, a_2, a_3, a_4$ real constants. Just like in the calculation in diffusion limit the distribution at  $r \rightarrow \infty$ is defined as the concentration of particle A $\rho_t(r \rightarrow \infty)=C_A$. Thus $a_1=C_A$ and due to the continuity of the density distribution , $a_3=-a_4$. Further, due to the continuity of the the flux $j_s(r)$ at $r=\sigma$ also $a_2$ and $a_3$ can be determined:
\begin{align}
 a_2&= C_A \left( \sqrt{\frac{D}{\lambda_{+}}} \tanh\left(\sigma \sqrt{\frac{\lambda_{+}}{D}}\right)-\sigma\right)  \\
 a_3&= \frac{C_A  \sqrt{\frac{D}{\lambda_{+}}}}{2 \cosh\left(\sigma \sqrt{\frac{\lambda_{+}}{D}}\right)}
\end{align}
The flux at  $r= \sigma$ can be written as:
\begin{align}
j^{s}(\sigma)=D \frac{\partial\rho_t(\sigma)}{\partial_{\sigma}}= -D \frac{a_2}{\sigma^2} 
\end{align}
Gauss's theorem states that the negative flux of a quantity through a closed surface is equal to the production of that quantity inside the volume. Further The change of complex AB is proportional to the change of A inside the volume of of the sphere with $r=\sigma$. The total flux and thus the change of AB can be written as:
\begin{align}
  \frac{d C_{AB} }{dt}&=- \int_{\partial V} j^{s}(\sigma) da= \int_{\partial V} D \frac{a_2} {\sigma^2}  da =- 4 \pi D a_2 C_B \\ &= 4 \pi D C_B  C_A \left(\sigma -\sqrt{\frac{D}{\lambda_{+}}} \tanh\left(\sigma \sqrt{\frac{\lambda_{+}}{D}}\right)\right)
\end{align}



\begin{comment}
 

\section{Kinetics of the Bi-Molecular Chemical Reaction in Solution}\label{bi-molecular}
The aim of this calculation is to derive the kinetics for the following reaction scheme: \ch{A + B <=>[ $k^{+}_{\mathrm{d}}$ ][ $k^{-}_{\mathrm{d}}$ ] AB }\newline
The derivation is calculated under the assumption of free diffusion of particle A and B with the diffusion constants $D_A$ and $D_B$ , respectively and without any interactions between them. 
The joint concentration field can be described by the Smoluchowski equation for a bi-molecular system in a solution:
\begin{align}
 \frac{\partial \rho_t(\bm{r}_A,\bm{r}_B)}{\partial t}=(D_A \nabla^{2}_{A}+D_B \nabla^{2}_{B}) \rho_t(\bm{r}_A,\bm{r}_B) \label{smolubi}
\end{align}
The complexity of the problem can be reduced by substituting the positions of the particles A and B with their relative distance $\bm{r}=\bm{r}_A-\bm{r}_B$. It is convenient to introduce even further substitutions:
\begin{align}
 D= D_A+D_B \qquad \qquad \bm{R}=\frac{D_B \bm{r}_A+ D_A \bm{r}_B}{D_A+D_B}
\end{align}
the Laplace operator in terms of new coordinates result in:
\begin{align}
\nabla^{2}_{A} = \left( \nabla_r+\frac{D_B}{D} \nabla_R \right)^2 \\
\nabla^{2}_{B} = \left( \nabla_r+\frac{D_A}{D} \nabla_R \right)^2 
\end{align}
Inserting these in \cref{smolubi} one gets:
\begin{align}
 \frac{\partial \tilde{\rho}_t(\bm{r},\bm{R})}{\partial t}=\left(D \nabla^{2}_{r}+\frac{D_B D_A}{D_A+D_B}\nabla^{2}_{R}\right) \tilde{\rho}_t(\bm{r},\bm{R})
\end{align}
The equation is describing two independent diffusion processes, one in
the coordinate $\bm{r}$ and one in the coordinate $\bm{R}$. The solution can be obtained by the product ansatz $\tilde{\rho}_t(\bm{r},\bm{R})=\rho_t(\bm{r})q_t(\bm{R})$. Integration over $\bm{R}$ results in:
\begin{align}
\frac{\partial \rho_t(\bm{r})}{\partial t}=D \nabla^{2}_{r} \rho_t(\bm{r}) +\frac{D_B D_A}{D_A+D_B} \nabla^{2}_{R} \rho_t(\bm{r}) \int_{\partial V} q_t(\bm{R}) d \bm{a}
\end{align}
In the previous equation the stokes theorem was applied. The second term is zero due to conservation of probability. The problem is isotropic, hence $r=|\bm{r}|$ and $\nabla^{2}_{\bm{r}}=\left(\partial_r+\frac{2}{r}\right)\partial$. The equation reduce to one dimension:
\begin{align}
\frac{\partial \rho_t(r)}{\partial t}=-\left(\frac{\partial}{\partial_r}+\frac{2}{r} \right) j_t(r) \qquad \qquad j_t(r)=D \frac{\partial\rho_t(r)}{\partial_r}
\end{align}
 The stationary distribution results in:
\begin{align}
 0 &=-\left(\frac{\partial}{\partial_r}+\frac{2}{r} \right) j^{s}_t(r) \\
 \frac{d j^{s}_t(r)}{j^{s}_t(r)}  &=- \frac{2}{r} dr\\
 j^{s}_t(r)&=A r^{-2}\\
 \rho^s(r)&=\rho^s(r_0)- \frac{\int_{r_0}^{r} j^{s}_t(r')dr'}{D}=\rho^s(r_0)+\frac{A}{D}\left(\frac{1}{r}-\frac{1}{r_0}\right)
\end{align}
Now assuming only a single B molecule being at the position $r=0$. Instantaneous reaction occur for $r\leq \sigma \Rightarrow \rho_t(r \leq \sigma)=0$. For $r \rightarrow \infty$ the distribution is than defined as the concentration of particle A $\rho_t(r \rightarrow \infty)=c_A$ and 
the Solutions for $\rho^{s}(r)$ and $j^{s}_t(r)$ for the boundary conditions are:
\begin{align}
 \rho^{s}(r)=C_A \left(1-\frac{\sigma}{r}\right) \qquad j^{s}_t(r)&=-D \sigma C_A r^{-2}
\end{align}
The change of the concentration of $C_{AB}$ is then: 
\begin{align}
 \frac{d C_{AB} }{d}=4 \pi \sigma D C_A C_B
\end{align}
By formulating the problem in relative distance from particle A and B. It was also reasonable to keep particle B at its initial position. The results shows the relation between the product of the concentrations and the concentration change.In the derivation of Michealis-Menten kinetics this is an assumption. 

 

\chapter{old stuff}
\section{Theory}
\subsection{Diffusion-controlled Reactions for Brownian Motion}
Chemical reactions are omnipresent in biological systems. Reactions are composed of reactants and products. These reactants and products are atoms or molecules with changing number over time during reactions. Studying chemical reactions often contains reaction kinetics. Reaction kinetics is about rates of chemical process. Enzymatic reactions e.g. play an important role in biological systems to reduce rates of reactions. The rates of reactions in solutions are not only governed by intrinsic reaction rates, which were addressed e.g. by Kramer's escape problem for two reactants, but also on rates at which the chemical participants diffuse into close proximity. In a reaction of the following type: \ch{A + B <>[ $k^{+}_{\mathrm{d}}$ ][ $k^{-}_{\mathrm{d}}$ ] AB <> [ $k^{+}_{\mathrm{a}}$ ][ $k^{-}_{\mathrm{a}}$ ] C}. \newline The Kramer's escape problem deals with the rates on the right side  $k^{\pm}_{\mathrm{a}}$. Smoluchowski deals with the rates on the other side $k^{\pm}_{\mathrm{d}}$. \newline  A theoretical approach on how fast two particles come together in a dilute system of hard spheres moving independently with Brownian motion have been studied by Marian von Smoluchowski in 1916 \cite{Smoluchowski1}. This was the first study on diffusion-limited reaction rates. A constant rate $k^{+}$ can be written as:
\begin{align}
 k^{+}=4 \pi (D_1+D_2)(R_1+R_2)=4 \pi (D_1+D_2) \sigma \label{reactionrate11}
\end{align}
with $\sigma = R_1+R_2$ the relative distance between the sphere centres.  It is a direct result of the diffusion equation. The calculation can be found in the appendix \ref{bi-molecular}. One particular area of research on which the Smoluchowski relation had significant impact in the last few decades is biology. This is unsurprising as a vast number of biomolecular systems involve dilute and minute diffusing molecular populations undergoing continuous reaction. Understanding how these biological systems operate is complicated and is in itself a whole field of research; systems biology. The Smoluchowski result has provided a very powerful tool for theoretical investigation of microscopic biochemical reaction-diffusion processes \cite{Flegg}. It was extended by P. Debye in 1942 to add intermolecular forces. However, especially in biological systems Brownian motion do not apply for all time-scales. As stated in the motivation these environments exhibit very often anomalous diffusion, which can be addressed by fBm. 
\newline
A related reaction type was studied by L. Michaelis and Maud L. Menten in 1913 \cite{Johnson2011}. Also Known as Michaelis-Menten kinetics:   
\ch{S + E <>[ $k_{\mathrm{1}}$ ][ $k'_{\mathrm{1}}$ ] E S <> [ $k_{\mathrm{2}}$ ] [ $k'_{\mathrm{2}}$ ]P + E}, with $k'_{\mathrm{2}}=0$. The assumption of irreversibility can be considers as a good approximation, if the concentration of the substrate  is a lot larger then the concentration of the Product $[S]\gg[P]$ or if the Gibbs free energy (released energy) is very large  $\Delta G \ll 0$ (Kramer's escape Problem). With a further quasi-steady-state approximation  ($k_{\mathrm{1}}[E][S]=k'_{\mathrm{1}}[ES]+k_{\mathrm{2}}[ES]$) the Michaelis-Menten equation results in:
\begin{align}
 v= \frac{d[P]}{dt}=V_{max} \frac{[S]}{K_M+[S]}  \qquad \text{ with } \qquad K_M=\frac{k'_{\mathrm{1}}+k_{\mathrm{2}}}{k_{\mathrm{1}}}
\end{align}
The derivation can be found in the appendix \ref{Menten_der} . In the first step the relation $\frac{d[ES]}{dt}\propto [E][S]$ is assumed. This is coherent with the results from the calculation for kinetics of bi-molecular reaction in solutions with the assumption of normal diffusion in \cref{bi-molecular}. However, in the environment of a living cell where there is a high concentration of proteins, the cytoplasm often behaves more like a gel than a liquid, limiting molecular movements and altering reaction rates \cite{Zhou2008}.

\begin{comment}
 Belousov-Zhabotinsky-Reaktion ?
 https://en.wikipedia.org/wiki/Reaction%E2%80%93diffusion_system interessint 
 Two-component reaction–diffusion equations

\section{Simulation and Outlook}
A software package revReaDDy was used to simulate reactions in a dilute system. It builds upon ReaDDy \cite{Johannesschoneberg2014} and is still under development. It is a particle based simulation software acting on a macromolecular level. For the following simulation Brownian motion was used as an integrator and will be replaced by fBm in the second half of the master thesis. RevReaDDy has periodic boundary conditions. In the following, possible input parameters will be mentioned.  Particle types with a radius and diffusion constant can be defined. Further, also the simulation box size can be varied. Different types of reactions can be incorporated. Their parameters are: 1. Intrinsic reaction rates $k_a$: They describe the speed of the reaction as soon as the reactants are in a close proximity. 2. The distance for close proximity. 3. Which particles take part in the reaction. \newline In the following, results from an enzymatic reaction will be shown. The reaction is a simplified version of Michaelis-Menten. That is what we intended to simulate. Formation of complexes is still not integrated in revReaDDy. A close reaction scheme to Michaelis-Menten  can be reduced to: \ch{S + E -> [ $k_{\mathrm{1}}$ ] P + E}. This kind of reaction type  is already integrated in ReaDDy and can be used. The concentrations over time for this reaction results in:
\begin{align}
 c_S(t)&=c_{s_0} e^{- t k_1  c_E} \\
 c_P(t)&=c_{s_0}\left(1- e^{-t k_1  c_E}\right)
\end{align}
for boundary conditions $c_P(0)=0$. The intrinsic reaction parameter is set to be infinite so that reactions occur immediately if particles surpass the reaction radius $\sigma$. This setup is completely diffusion limited and \cref{reactionrate11} can be applied. The resulting time dependent  concentrations are:
\begin{align}
 c_S(t)&=c_{s_o} e^{- t 4 \pi (D_1+D_2) \sigma  c_E}  \label{substratetheo}\\
 c_P(t)&=c_{s_0} \left(1- e^{-t 4 \pi (D_1+D_2) \sigma  c_E}\right)
\end{align}
This setup has been simulated with only one enzyme. The time dependent particle number of the substrate  $S(t)$ was recorded for different diffusion constants and compared to the theoretical values. The result can be seen in \cref{fig:reactionssimulation}. The theory is fitting to the exponential decay in the simulation. This simulation shows the influence of $D$ on reactions. 
\begin{figure}[h!]
  \centering
  \includegraphics[width=\linewidth]{./data/besta.png}
  \captionsetup{width=0.9\linewidth}
  \captionof{figure}{Substrate particle number $S(t)$ for different Diffusion constants $D$ of the enzyme and substrate. With fitted theoretical curves from equation \cref{substratetheo}. The input parameters for RevReaDDy are: box size$=10^3nm$,reaction distance $=3$,intrinsic reaction rate$=10^{25}$, timesteps$=1000$,$S(0)=300$.}
  \label{fig:reactionssimulation}
\end{figure}
\newline \noindent In the second half of the master thesis fBm is going to be integrated in RevReaDDy. Similar simulations with fBm are going to be studied and related to Brownian motion. Spatial distributions of the reactants are going to be studied. The algorithm for fBm uses his velocity autocorrelation function. In principle it should be possible to integrate also different VACFs. The fBm integrator would result in an more general integrator, which could be used to model environments from real experiments. Including the VACF in the integrator may be an elegant way of adding an approximation due to the experimental environment. 

%\subsection{Code:Gebrochen-rationale Brownische Bewegung}
%\lstinputlisting[language=Python]{../simulation.py}
\end{comment}

\nocite{}

%\printindex
\bibliography{literatur}


\end{document}
